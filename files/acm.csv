"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"CTFF299M","conferencePaper","2019","Correll, Michael","Ethical dimensions of visualization research","Proceedings of the 2019 CHI conference on human factors in computing systems","978-1-4503-5970-2","","10.1145/3290605.3300418","https://doi.org/10.1145/3290605.3300418","Visualizations have a potentially enormous influence on how data are used to make decisions across all areas of human endeavor. However, it is not clear how this power connects to ethical duties: what obligations do we have when it comes to visualizations and visual analytics systems, beyond our duties as scientists and engineers? Drawing on historical and contemporary examples, I address the moral components of the design and use of visualizations, identify some ongoing areas of visualization research with ethical dilemmas, and propose a set of additional moral obligations that we have as designers, builders, and researchers of visualizations.","2019","2024-07-07 16:25:36","2024-07-07 16:25:36","","1–13","","","","","","","Chi '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3290605.3300418 Number of pages: 13 Place: Glasgow, Scotland Uk","","","","ethics; information visualization; visual analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49D3GL4N","journalArticle","2017","Gotz, David; Sun, Shun; Cao, Nan; Kundu, Rita; Meyer, Anne-Marie","Adaptive contextualization methods for combating selection bias during high-dimensional visualization","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/3009973","https://doi.org/10.1145/3009973","Large and high-dimensional real-world datasets are being gathered across a wide range of application disciplines to enable data-driven decision making. Interactive data visualization can play a critical role in allowing domain experts to select and analyze data from these large collections. However, there is a critical mismatch between the very large number of dimensions in complex real-world datasets and the much smaller number of dimensions that can be concurrently visualized using modern techniques. This gap in dimensionality can result in high levels of selection bias that go unnoticed by users. The bias can in turn threaten the very validity of any subsequent insights. This article describes Adaptive Contextualization (AC), a novel approach to interactive visual data selection that is specifically designed to combat the invisible introduction of selection bias. The AC approach (1) monitors and models a user’s visual data selection activity, (2) computes metrics over that model to quantify the amount of selection bias after each step, (3) visualizes the metric results, and (4) provides interactive tools that help users assess and avoid bias-related problems. This article expands on an earlier article presented at ACM IUI 2016 [16] by providing a more detailed review of the AC methodology and additional evaluation results.","2017-11","2024-07-07 16:25:36","2024-07-07 16:25:36","","","","4","7","","ACM Trans. Interact. Intell. Syst.","","","","","","","","","","","","","","","Citation Key: 10.1145/3009973 Number of pages: 23 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 17 tex.issue_date: December 2017","","","","exploratory analysis; intelligent visual interfaces; selection bias; visual analytics; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NDZJY5GL","conferencePaper","2008","Suh, Bongwon; Chi, Ed H.; Kittur, Aniket; Pendleton, Bryan A.","Lifting the veil: improving accountability and social transparency in Wikipedia with wikidashboard","Proceedings of the SIGCHI conference on human factors in computing systems","978-1-60558-011-1","","10.1145/1357054.1357214","https://doi.org/10.1145/1357054.1357214","Wikis are collaborative systems in which virtually anyone can edit anything. Although wikis have become highly popular in many domains, their mutable nature often leads them to be distrusted as a reliable source of information. Here we describe a social dynamic analysis tool called WikiDashboard which aims to improve social transparency and accountability on Wikipedia articles. Early reactions from users suggest that the increased transparency afforded by the tool can improve the interpretation, communication, and trustworthiness of Wikipedia articles.","2008","2024-07-07 16:25:36","2024-07-07 16:25:36","","1037–1040","","","","","","","Chi '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1357054.1357214 Number of pages: 4 Place: Florence, Italy","","","","accountability; collaboration; social transparency; trust; visualization; wiki; wikidashboard; wikipedia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9DHI9ZIU","conferencePaper","2022","Kuflik, Tsvi; Dodge, Jonathan; Kleanthous Loizou, Styliani; Lim, Brian; Negreanu, Carina; Shulner-Tal, Avital; Stumpf, Simone","TExSS 22: Transparency and explanations in smart systems","Companion proceedings of the 27th international conference on intelligent user interfaces","978-1-4503-9145-0","","10.1145/3490100.3511165","https://doi.org/10.1145/3490100.3511165","Smart systems, such as decision support or recommender systems, continue to prove challenging for people to understand, but are nonetheless ever more pervasive based on the promise of harnessing rich data sources that are becoming available in every domain. These systems tend to be opaque, raising important concerns about how to discover and account for fairness or bias issues. The workshop on Transparency and Explanations in Smart Systems (TExSS) welcomes researchers and practitioners interested in exchanging ideas for overcoming the design, development, and evaluation issues in intelligent user interfaces. Specifically, we will focus on barriers preventing better reliability, trainability, usability, trustworthiness, fairness, accountability, and transparency. This year's theme is “Responsible, Explainable AI for Inclusivity and Trust”, emphasizing the importance of responsibility that tech-industry and developers have towards the design, implementation and evaluation of explainable, inclusive and trustworthy human-AI interaction.","2022","2024-07-07 16:25:36","2024-07-07 16:25:36","","16–17","","","","","","","IUI '22 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3490100.3511165 Number of pages: 2 Place: Helsinki, Finland","","","","accountability; explanations; fairness; intelligent systems; intelligibility; machine learning; transparency; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T8GM5NHY","conferencePaper","2021","Smith-Renner, Alison Marie; Loizou, Styliani Kleanthous; Dodge, Jonathan; Dugan, Casey; Lee, Min Kyung; Lim, Brian Y; Kuflik, Tsvi; Sarkar, Advait; Shulner-Tal, Avital; Stumpf, Simone","TExSS: Transparency and explanations in smart systems","Companion proceedings of the 26th international conference on intelligent user interfaces","978-1-4503-8018-8","","10.1145/3397482.3450705","https://doi.org/10.1145/3397482.3450705","Smart systems that apply complex reasoning to make decisions and plan behavior, such as decision support systems and personalized recommendations, are difficult for users to understand. Algorithms allow the exploitation of rich and varied data sources, in order to support human decision-making and/or taking direct actions; however, there are increasing concerns surrounding their transparency and accountability, as these processes are typically opaque to the user. Transparency and accountability have attracted increasing interest to provide more effective system training, better reliability and improved usability. This workshop provides a venue for exploring issues that arise in designing, developing and evaluating intelligent user interfaces that provide system transparency or explanations of their behavior. In addition, we focus on approaches to mitigate algorithmic biases that can be applied by researchers, even without access to a given system’s inter-workings, such as awareness, data provenance, and validation.","2021","2024-07-07 16:25:36","2024-07-07 16:25:36","","24–25","","","","","","","IUI '21 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3397482.3450705 Number of pages: 2 Place: College Station, TX, USA","","","","accountability; explanations; fairness; intelligent systems; intelligibility; machine learning; transparency; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5LTE4R6Y","conferencePaper","2020","Smith-Renner, Alison; Kleanthous, Styliani; Lim, Brian; Kuflik, Tsvi; Stumpf, Simone; Otterbacher, Jahna; Sarkar, Advait; Dugan, Casey; Shulner, Avital","ExSS-ATEC: Explainable smart systems for algorithmic transparency in emerging technologies 2020","Companion proceedings of the 25th international conference on intelligent user interfaces","978-1-4503-7513-9","","10.1145/3379336.3379361","https://doi.org/10.1145/3379336.3379361","Smart systems that apply complex reasoning to make decisions and plan behavior, such as decision support systems and personalized recommendations, are difficult for users to understand. Algorithms allow the exploitation of rich and varied data sources, in order to support human decision-making and/or taking direct actions; however, there are increasing concerns surrounding their transparency and accountability, as these processes are typically opaque to the user. Transparency and accountability have attracted increasing interest to provide more effective system training, better reliability and improved usability. This workshop will provide a venue for exploring issues that arise in designing, developing and evaluating intelligent user interfaces that provide system transparency or explanations of their behavior. In addition, our goal is to focus on approaches to mitigate algorithmic biases that can be applied by researchers, even without access to a given system's inter-workings, such as awareness, data provenance, and validation.","2020","2024-07-07 16:25:36","2024-07-07 16:25:36","","7–8","","","","","","","IUI '20 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3379336.3379361 Number of pages: 2 Place: Cagliari, Italy","","","","accountability; Explanations; fairness; intelligent systems; intelligibility; machine learning; transparency; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHVFWX4X","conferencePaper","2017","Park, Sora; Gil-Garcia, J. Ramon","Understanding transparency and accountability in open government ecosystems: The case of health data visualizations in a state government","Proceedings of the 18th annual international conference on digital government research","978-1-4503-5317-5","","10.1145/3085228.3085318","https://doi.org/10.1145/3085228.3085318","Many researchers of open government data raised the question as to whether transparency also promotes accountability. Concerning the unclear relationship between transparency and accountability, this case study first develops the conception of accountability in the context of open government and finds that accountability relates to the organizational need for an assessment of policy goals. This paper then examines the process in which a state health agency implements data visualization tools in an attempt to enhance the outcome of its open data policy goals. Drawing on the results from semi-structured interviews with a diverse set of internal users at the state agency, this case study provides some evidence as to how the gap between transparency and accountability can be closed at the organizational level. It also finds that data intermediaries can help government agencies overcome their resource constraints by critically assessing data usability while providing the technological expertise to align their open data policy goals with user expectations. Future research is necessary to examine the role of data intermediaries in wider open data ecosystems including multiple external stakeholders.","2017","2024-07-07 16:25:36","2024-07-07 16:25:36","","39–47","","","","","","","dg.o '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3085228.3085318 Number of pages: 9 Place: Staten Island, NY, USA","","","","Accountability; Data Intermediaries; Health Data; Open Data; Open Data Ecosystem; Transparency; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LL7D82LK","conferencePaper","2014","González, Juan Carlos; Garcia, Jaime; Cortés, Federico; Carpy, David","Government 2.0: a conceptual framework and a case study using Mexican data for assessing the evolution towards open governments","Proceedings of the 15th annual international conference on digital government research","978-1-4503-2901-9","","10.1145/2612733.2612742","https://doi.org/10.1145/2612733.2612742","In this paper, we propose a theoretical framework to analyze open government data, constituted by a supply and demand mechanism. Besides, we discuss the implementation of several digital government initiatives around the world, including relevant Mexican cases. And finally, we develop an example of data visualization for the Mexican federal budget, specifically the investment portfolio. The objective is to prove that data can be transformed to make it understandable to the regular user who lacks technical and technological skills, and therefore an efficient tool for citizens and policy makers.","2014","2024-07-07 16:25:36","2024-07-07 16:25:36","","124–136","","","","","","","dg.o '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2612733.2612742 Number of pages: 13 Place: Aguascalientes, Mexico","","","","accountability; budget; e-Government; information access; open data; open government; transparency; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6EEPNJFS","conferencePaper","2021","Rathore, Archit; Dev, Sunipa; Phillips, Jeff M.; Srikumar, Vivek; Wang, Bei","A visual tour of bias mitigation techniques for word representations","Proceedings of the 27th ACM SIGKDD conference on knowledge discovery &amp; data mining","978-1-4503-8332-5","","10.1145/3447548.3470807","https://doi.org/10.1145/3447548.3470807","Word vector embeddings have been shown to contain and amplify biases in data they are extracted from. Consequently, many techniques have been proposed to identify, mitigate, and attenuate these biases in word representations. In this tutorial, we will review a collection of state-of-the-art debiasing techniques. To aid this, we provide an open source web-based visualization tool and offer hands-on experience in exploring the effects of these debiasing techniques on the geometry of high-dimensional word vectors. To help understand how various debiasing techniques change the underlying geometry, we decompose each technique into interpretable sequences of primitive operations, and study their effect on the word vectors using dimensionality reduction and interactive visual exploration.","2021","2024-07-07 16:25:36","2024-07-07 16:25:36","","4064–4065","","","","","","","Kdd '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3447548.3470807 Number of pages: 2 Place: Virtual Event, Singapore","","","","bias; fair nlp; fairness; responsible ai; visualization; visualizing bias","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RTLQZSQA","conferencePaper","2021","van Berkel, Niels; Goncalves, Jorge; Russo, Daniel; Hosio, Simo; Skov, Mikael B.","Effect of information presentation on fairness perceptions of machine learning predictors","Proceedings of the 2021 CHI conference on human factors in computing systems","978-1-4503-8096-6","","10.1145/3411764.3445365","https://doi.org/10.1145/3411764.3445365","The uptake of artificial intelligence-based applications raises concerns about the fairness and transparency of AI behaviour. Consequently, the Computer Science community calls for the involvement of the general public in the design and evaluation of AI systems. Assessing the fairness of individual predictors is an essential step in the development of equitable algorithms. In this study, we evaluate the effect of two common visualisation techniques (text-based and scatterplot) and the display of the outcome information (i.e., ground-truth) on the perceived fairness of predictors. Our results from an online crowdsourcing study (N = 80) show that the chosen visualisation technique significantly alters people’s fairness perception and that the presented scenario, as well as the participant’s gender and past education, influence perceived fairness. Based on these results we draw recommendations for future work that seeks to involve non-experts in AI fairness evaluations.","2021","2024-07-07 16:25:36","2024-07-07 16:25:36","","","","","","","","","Chi '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3411764.3445365 Number of pages: 13 Place: Yokohama, Japan tex.articleno: 245","","","","AI; Artificial intelligence; crowdsourcing; fairness; layperson; machine learning; ML.; predictor selection; transparency; visualisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7JUXMSZR","conferencePaper","2021","Ghai, Bhavya; Hoque, Md Naimul; Mueller, Klaus","WordBias: An interactive visual tool for discovering intersectional biases encoded in word embeddings","Extended abstracts of the 2021 CHI conference on human factors in computing systems","978-1-4503-8095-9","","10.1145/3411763.3451587","https://doi.org/10.1145/3411763.3451587","Intersectional bias is a bias caused by an overlap of multiple social factors like gender, sexuality, race, disability, religion, etc. A recent study has shown that word embedding models can be laden with biases against intersectional groups like African American females, etc. The first step towards tackling intersectional biases is to identify them. However, discovering biases against different intersectional groups remains a challenging task. In this work, we present WordBias, an interactive visual tool designed to explore biases against intersectional groups encoded in static word embeddings. Given a pretrained static word embedding, WordBias computes the association of each word along different groups like race, age, etc. and then visualizes them using a novel interactive interface. Using a case study, we demonstrate how WordBias can help uncover biases against intersectional groups like Black Muslim Males, Poor Females, etc. encoded in word embedding. In addition, we also evaluate our tool using qualitative feedback from expert interviews. The source code for this tool can be publicly accessed for reproducibility at github.com/bhavyaghai/WordBias.","2021","2024-07-07 16:25:36","2024-07-07 16:25:36","","","","","","","","","Chi ea '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3411763.3451587 Number of pages: 7 Place: Yokohama, Japan tex.articleno: 429","","","","Algorithmic Fairness; Visual Analytics; Word Embeddings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FNIA5CVU","conferencePaper","2016","Sänger, Johannes; Hänsch, Norman; Glass, Brian; Benenson, Zinaida; Landwirth, Robert; Sasse, M. Angela","Look before you leap: Improving the users' ability to detect fraud in electronic marketplaces","Proceedings of the 2016 CHI conference on human factors in computing systems","978-1-4503-3362-7","","10.1145/2858036.2858555","https://doi.org/10.1145/2858036.2858555","Reputation systems in current electronic marketplaces can easily be manipulated by malicious sellers in order to appear more reputable than appropriate. We conducted a controlled experiment with 40 UK and 41 German participants on their ability to detect malicious behavior by means of an eBay-like feedback profile versus a novel interface involving an interactive visualization of reputation data. The results show that participants using the new interface could better detect and understand malicious behavior in three out of four attacks (the overall detection accuracy 77","2016","2024-07-07 16:25:36","2024-07-07 16:25:36","","3870–3882","","","","","","","Chi '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2858036.2858555 Number of pages: 13 Place: San Jose, California, USA","","","","context-based attacks; fraud detection; reputation systems; trust; visual analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"58KILCTW","conferencePaper","2012","Jianu, Radu; Laidlaw, David","An evaluation of how small user interface changes can improve scientists' analytic strategies","Proceedings of the SIGCHI conference on human factors in computing systems","978-1-4503-1015-4","","10.1145/2207676.2208704","https://doi.org/10.1145/2207676.2208704","Subtle changes in analysis system interfaces can be used purposely to alter users' analytic behaviors. In a controlled study subjects completed three analyses at one-week intervals using an analysis support system. Control subjects used one interface in all sessions. Test subjects used modified versions in the last two sessions: a first set of changes aimed at increasing subjects' use of the system and their consideration of alternative hypotheses; a second set of changes aimed at increasing the amount of evidence collected. Results show that in the second session test subjects used the interface 39","2012","2024-07-07 16:25:36","2024-07-07 16:25:36","","2953–2962","","","","","","","Chi '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2207676.2208704 Number of pages: 10 Place: Austin, Texas, USA","","","","analytic biases; persuasive technology; visual analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BXHPAIEJ","conferencePaper","2023","Bhattacharya, Aditya; Ooge, Jeroen; Stiglic, Gregor; Verbert, Katrien","Directive explanations for monitoring the risk of diabetes onset: Introducing directive data-centric explanations and combinations to support what-if explorations","Proceedings of the 28th international conference on intelligent user interfaces","9798400701061","","10.1145/3581641.3584075","https://doi.org/10.1145/3581641.3584075","Explainable artificial intelligence is increasingly used in machine learning (ML) based decision-making systems in healthcare. However, little research has compared the utility of different explanation methods in guiding healthcare experts for patient care. Moreover, it is unclear how useful, understandable, actionable and trustworthy these methods are for healthcare experts, as they often require technical ML knowledge. This paper presents an explanation dashboard that predicts the risk of diabetes onset and explains those predictions with data-centric, feature-importance, and example-based explanations. We designed an interactive dashboard to assist healthcare experts, such as nurses and physicians, in monitoring the risk of diabetes onset and recommending measures to minimize risk. We conducted a qualitative study with 11 healthcare experts and a mixed-methods study with 45 healthcare experts and 51 diabetic patients to compare the different explanation methods in our dashboard in terms of understandability, usefulness, actionability, and trust. Results indicate that our participants preferred our representation of data-centric explanations that provide local explanations with a global overview over other methods. Therefore, this paper highlights the importance of visually directive data-centric explanation method for assisting healthcare experts to gain actionable insights from patient health records. Furthermore, we share our design implications for tailoring the visual representation of different explanation methods for healthcare experts.","2023","2024-07-07 16:25:36","2024-07-07 16:25:36","","204–219","","","","","","","Iui '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3581641.3584075 Number of pages: 16 Place: Sydney, NSW, Australia","","","","Explainable AI; Human-centered AI; Interpretable AI; Responsible AI; Visual Analytics; XAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DV4Q6TJJ","conferencePaper","2022","Stoll, Elena; Urban, Adam; Ballin, Philipp; Kammer, Dietrich","Can explainable AI foster trust in a customer dialogue system?","Proceedings of the 2022 international conference on advanced visual interfaces","978-1-4503-9719-3","","10.1145/3531073.3534481","https://doi.org/10.1145/3531073.3534481","In this poster paper we present a web user study about a customer dialogue system, in which participants assigned tickets based on an automatic classification to different departments and answered questions about the perceived classification performance. Completion times were significantly shorter when offering explanations on the classification process, while task success and trust in the interface did not depend on showing explanations or not. Based on the results, future studies should be confined to smaller scopes and investigate more techniques for explainable AI.","2022","2024-07-07 16:25:36","2024-07-07 16:25:36","","","","","","","","","Avi '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3531073.3534481 Number of pages: 3 Place: Frascati, Rome, Italy tex.articleno: 56","","","","Explainable AI; Information Visualization; Transparency; Trust","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UK8HZ5ZW","conferencePaper","1994","Stone, Maureen C.; Fishkin, Ken; Bier, Eric A.","The movable filter as a user interface tool","Proceedings of the SIGCHI conference on human factors in computing systems","0-89791-650-6","","10.1145/191666.191774","https://doi.org/10.1145/191666.191774","","1994","2024-07-07 16:25:37","2024-07-07 16:25:37","","306–312","","","","","","","Chi '94","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/191666.191774 Number of pages: 7 Place: Boston, Massachusetts, USA","","","","editing; graphics; lens; macro; transparent; viewing filter; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U6B9SS8Z","conferencePaper","1995","Interrante, Victoria; Fuchs, Henry; Pizer, Stephen","Enhancing transparent skin surfaces with ridge and valley lines","Proceedings of the 6th conference on visualization '95","0-8186-7187-4","","","","There are many applications that can benefit from the simultaneous display of multiple layers of data. The objective in these cases is to render the layered surfaces in such a way that the outer structures can be seen and seen through at the same time. This paper focuses on the particular application of radiation therapy treatment planning, in which physicians need to understand the three-dimensional distribution of radiation dose in the context of patient anatomy. We describe a promising technique for communicating the shape and position of the transparent skin surface while at the same time minimally occluding underlying isointensity dose surfaces and anatomical objects: adding a sparse, opaque texture comprised of a small set of carefully-chosen lines. We explain the perceptual motivation for explicitly drawing ridge and valley curves on a transparent surface, describe straightforward mathematical techniques for detecting and rendering these lines, and propose a small number of reasonably effective methods for selectively emphasizing the most perceptually relevant lines in the display.","1995","2024-07-07 16:25:37","2024-07-07 16:25:37","","52","","","","","","","Vis '95","","","","IEEE Computer Society","USA","","","","","","","","Citation Key: 10.5555/832271.833836","","","","medical imaging; transparency; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G4M2Q297","conferencePaper","2021","Bhatt, Umang; Antorán, Javier; Zhang, Yunfeng; Liao, Q. Vera; Sattigeri, Prasanna; Fogliato, Riccardo; Melançon, Gabrielle; Krishnan, Ranganath; Stanley, Jason; Tickoo, Omesh; Nachman, Lama; Chunara, Rumi; Srikumar, Madhulika; Weller, Adrian; Xiang, Alice","Uncertainty as a form of transparency: Measuring, communicating, and using uncertainty","Proceedings of the 2021 AAAI/ACM conference on AI, ethics, and society","978-1-4503-8473-5","","10.1145/3461702.3462571","https://doi.org/10.1145/3461702.3462571","Algorithmic transparency entails exposing system properties to various stakeholders for purposes that include understanding, improving, and contesting predictions. Until now, most research into algorithmic transparency has predominantly focused on explainability. Explainability attempts to provide reasons for a machine learning model's behavior to stakeholders. However, understanding a model's specific behavior alone might not be enough for stakeholders to gauge whether the model is wrong or lacks sufficient knowledge to solve the task at hand. In this paper, we argue for considering a complementary form of transparency by estimating and communicating the uncertainty associated with model predictions. First, we discuss methods for assessing uncertainty. Then, we characterize how uncertainty can be used to mitigate model unfairness, augment decision-making, and build trustworthy systems. Finally, we outline methods for displaying uncertainty to stakeholders and recommend how to collect information required for incorporating uncertainty into existing ML pipelines. This work constitutes an interdisciplinary review drawn from literature spanning machine learning, visualization/HCI, design, decision-making, and fairness. We aim to encourage researchers and practitioners to measure, communicate, and use uncertainty as a form of transparency.","2021","2024-07-07 16:25:37","2024-07-07 16:25:37","","401–413","","","","","","","Aies '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3461702.3462571 Number of pages: 13 Place: Virtual Event, USA","","","","machine learning; transparency; uncertainty; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5D5LEJ2","conferencePaper","2020","Zhang, Hao; Zhang, Zhishu; Xia, Luyao; Wang, Sheng; Zhao, Rongyong; Chen, Xiang; Liu, Steven","Augmented reality-based auxiliary device for workshop logistics delivery","Proceedings of the 2020 international conference on computing, networks and internet of things","978-1-4503-7771-3","","10.1145/3398329.3398364","https://doi.org/10.1145/3398329.3398364","Indoor logistics between machining centers is significant to deliver the work-pieces or components just in time a workshop. However, the existing of order disturbance caused by rush order inserting problem, the opaqueness of work in process (WIP) and line-side storage information often increase the difficulty of delivery and even lead to delivery mistakes. To solve the problems above, this paper introduces the augmented reality (AR) technology into a visual management layer. The guidance module diagram of workshop logistics is put forward. Feature-point detection algorithm and description algorithm used for AR is designed. Euclidean distance is defined for two high-dimensional features matching. To validate the approach, an engineering case about the visible delivery of the cylinder shells and piston rod on the CDL pipeline is studied. By using of visualization technology, the production and delivery information of materials can be transmitted to the operators in a comprehensive, real-time and accurate mode, the interaction between operators and equipment can be enhanced, and the entire process from order to production of the workshop products visual management and guidance can be advanced.","2020","2024-07-07 16:25:37","2024-07-07 16:25:37","","117–121","","","","","","","Cniot '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3398329.3398364 Number of pages: 5 Place: Sanya, China","","","","Augmented Reality; Feature Extraction; Transparency; Visualization; Workshop Logistics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TUACRGIU","conferencePaper","2023","Gupta, Shubhangi","Mapping the smart city: Participatory approaches to XAI","Companion publication of the 2023 ACM designing interactive systems conference","978-1-4503-9898-5","","10.1145/3563703.3593063","https://doi.org/10.1145/3563703.3593063","How can we explain the broad and uneven spatial effects of Machine Learning (ML) algorithms that mediate the everyday lives of smart city residents? The discriminatory impacts of civic algorithms remain opaque to city inhabitants and experts alike. Current Explainable AI (XAI) approaches, while influential, are limited in their ability to explain the inequitable algorithmic spatial effects in an accessible, critical, and grounded manner. My thesis explores the potential of participatory mapping as a critical and collaborative technique to address these limits. My work draws on (1) scholarship on critical data and algorithmic studies, (2) qualitative research with domain experts from history and criminology, and (3) participatory mapping sessions with city residents and ML practitioners. Ultimately, my research will inform the design of a toolkit to help people in classrooms and community centers collaboratively reflect on how city residents may unevenly experience the impact of artificially intelligent systems guiding contemporary urban life.","2023","2024-07-07 16:25:37","2024-07-07 16:25:37","","1–6","","","","","","","DIS '23 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3563703.3593063 Number of pages: 6 Place: Pittsburgh, PA, USA","","","","Explainable AI; Mapping; Participatory Methods; Smart city; Transparency; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FY8EK3XT","conferencePaper","2023","Gupta, Shubhangi; Loukissas, Yanni Alexander","Making smart cities explainable: What XAI can learn from the “ghost map”","Extended abstracts of the 2023 CHI conference on human factors in computing systems","978-1-4503-9422-2","","10.1145/3544549.3585847","https://doi.org/10.1145/3544549.3585847","How can we visualize civic algorithms in ways that illuminate both their positive and negative spatial impacts? Civic algorithms guide everyday decisions that cumulatively create city life. Yet, their broader effects remain invisible to their creators and city inhabitants. Recent scholarship on “algorithmic harms” presents an urgent need to make smart cities explainable. We argue that existing Explainable AI (XAI) approaches are limited across four important dimensions: accessibility, cultural reflexivity, situatedness, and visibility into internal representations. Our research explores the potential of conventional maps in addressing these limits and providing what we call “grounded explanations”. As a salient example, we harness the historical case of the “Ghost Map”, designed by John Snow to visualize and resolve the 1854 London Cholera epidemic. We believe that such examples can help the XAI community learn from the cultural history of city representations, as they seek to establish public processes for explaining and evaluating “smart cities”.","2023","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","Chi ea '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3544549.3585847 Number of pages: 8 Place: Hamburg, Germany tex.articleno: 199","","","","Algorithmic audits; Explainable AI; Maps; Smart city; Transparency; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"98S7AKRP","journalArticle","2013","Easa, Haider K.; Mantiuk, Rafał K.; Lim, Ik Soo","Evaluation of monocular depth cues on a high-dynamic-range display for visualization","ACM Trans. Appl. Percept.","","1544-3558","10.1145/2504568","https://doi.org/10.1145/2504568","The aim of this work is to identify the depth cues that provide intuitive depth-ordering when used to visualize abstract data. In particular we focus on the depth cues that are effective on a high-dynamic-range (HDR) display: contrast and brightness. In an experiment participants were shown a visualization of the volume layers at different depths with a single isolated monocular cue as the only indication of depth. The observers were asked to identify which slice of the volume appears to be closer. The results show that brightness, contrast and relative size are the most effective monocular depth cues for providing an intuitive depth ordering.","2013-08","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","3","10","","","","","","","","","","","","","","","","","Citation Key: 10.1145/2504568 Number of pages: 13 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 16 tex.issue_date: August 2013","","","","brightness; contrast; depth ordering; depth perception; HDR; monocular depth cues; transparency; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PUFTBWHB","conferencePaper","2017","Degbelo, Auriol","Linked data and visualization: Two sides of the transparency coin","Proceedings of the 3rd ACM SIGSPATIAL workshop on smart cities and urban analytics","978-1-4503-5495-0","","10.1145/3152178.3152191","https://doi.org/10.1145/3152178.3152191","Transparency is an important element of smart cities, and ongoing work is exploring the use of available open data to maximize it. This position paper argues that Linked Data and visualization play similar roles, for different agents, in this context. Linked Data increases transparency for machines, while visualization increases transparency for humans. The work also proposes a quantitative approach to the evaluation of visualization insights which rests on two premises: (i) visualizations could be modelled as a set of statements made by authors at some point in time, and (ii) statements made by experts could be used as ground truth while evaluating how much insights are effectively conveyed by visualizations on the Web. Drawing on the linked data rating scheme of Tim Berners-Lee, the paper proposes a five-stars rating scheme for visualizations on the Web. The ideas suggested are relevant to the development of techniques to automatically assess the transparency level of existing visualizations on the Web.","2017","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","UrbanGIS'17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3152178.3152191 Number of pages: 8 Place: Redondo Beach, CA, USA tex.articleno: 13","","","","Evaluation; Linked Data; Rating Scheme; Smart City; Transparency; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G527IZF4","conferencePaper","2021","Sturdee, Miriam; Thornton, Lauren; Wimalasiri, Bhagya; Patil, Sameer","A visual exploration of cybersecurity concepts","Proceedings of the 13th conference on creativity and cognition","978-1-4503-8376-9","","10.1145/3450741.3465252","https://doi.org/10.1145/3450741.3465252","Cybersecurity-related concepts can be difficult to explain or summarise. The complexity associated with these concepts is compounded by the impact of rapid technological changes and the contextual nature of the meaning ascribed to the various themes. Since visual imagery is often employed in articulation and explanation, we conducted a study in which we asked participants to sketch their understanding of cybersecurity concepts. Based on an analysis of these sketches and subsequent discussions with participants, we make the case for the use of sketching and visuals as a tool for cybersecurity research. Our collection of sketches and icons can further serve as the seed for a visual vocabulary for cybersecurity-related interfaces and communication.","2021","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","C&amp;C '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3450741.3465252 Number of pages: 10 Place: Virtual Event, Italy tex.articleno: 46","","","","cybersecurity; icons; imagery; privacy; risk; sketching; trust; visualisation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QW4CV3I4","conferencePaper","2014","Kim, Tiffany Hyun-Jin","Challenges of establishing trust in online entities and beyond","Proceedings of the 4th international workshop on trustworthy embedded devices","978-1-4503-3149-4","","10.1145/2666141.2668385","https://doi.org/10.1145/2666141.2668385","In today's Internet, authenticating online entities is challenging since people lack the real-world cues upon which to base their context-dependent trust decisions. For example, how can a user confirm that a Facebook invitation truly originates from the claimed sender, as anyone can trivially set up a bogus online identity with someone else's photo? Given an SSL certificate warning, how can a user validate it be- fore proceeding, as the certificate could be legitimate (e.g., the certificate is signed by a legitimate authority that the browser does not recognize) or malicious (e.g., it is signed by a compromised CA)? This talk demonstrates that providing useful evidence can empower users to make informed context-dependent trust decisions regarding previously unknown entities in the context of identity and public-key authentication. We first introduce an identity authentication logic called RelationGram that visualizes interpersonal tie strength of virtual entities using both physical and social proximities [2,4]. RelationGram enables casual users to authenticate online identities in a safe and easy manner, and build trust in previously unknown online entities. We then introduce new public-key validation proposals called Accountable Key Infrastructure (AKI) [3] and Attack Resilient Public-Key Infrastructure (ARPKI) [1] that reduce the amount of trust in any single entity to improve the resilience of the current PKI systems. AKI and ARPKI support trust agility such that entities select a security policy for their public-key certificates, and checks and balances such that entities monitor each other for misbehavior and prevent a single point of failure. When users are given pieces of evidence to which they can easily relate, they can make context-dependent authentication decisions online and build trust in online entities. As concluding remarks, we highlight some of the remaining challenges and future research directions to truly empower users to make informed trust decisions.","2014","2024-07-07 16:25:37","2024-07-07 16:25:37","","49","","","","","","","TrustED '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2666141.2668385 Number of pages: 1 Place: Scottsdale, Arizona, USA","","","","accountability; public-key infrastructure; tie-strength visualization; trust evidence","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S67QRJCV","conferencePaper","2017","Hasan, Syed Ziaul; Stapleton, Adam; Cadora, Eric; Sengupta, Promita; Rahman, Mustafiz","The bangladesh justice audit","Proceedings of the 10th international conference on theory and practice of electronic governance","978-1-4503-4825-6","","10.1145/3047273.3047396","https://doi.org/10.1145/3047273.3047396","The Bangladesh Constitution guarantees human rights, freedom, equality, justice and rule of law for all citizens. Article 33(1) ensures the rights for each citizen to legal support and article 35(3) affirms that every person accused of a criminal offence shall have the right to a speedy and public trial. The existing policy framework of the Government of Bangladesh (GoB) also emphasizes good governance. The Government in association with various national and international partners is wholeheartedly working to achieve its commitments in the Constitution, legal and policy framework.However, the criminal justice system in Bangladesh is still facing challenges. Courts have millions of cases backlogged and prisons are over 200","2017","2024-07-07 16:25:37","2024-07-07 16:25:37","","123–126","","","","","","","Icegov '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3047273.3047396 Number of pages: 4 Place: New Delhi AA, India","","","","advocacy; application; audit; Bangladesh; case management; citizen; communication; court management; credibility; criminal; criminal justice system; data collection; development; digital; digitization; evidence; Governance; graphics; information; Justice; justice reform; justice system; law; legal; open; ownership; participation; policy; political; politics; reform; sustainable; systematic; transparency; triangulation; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DE3ZKRDL","conferencePaper","2023","Jones, Corinne","Representations and privacy: Methodological questions for social media data","Proceedings of the 41st ACM international conference on design of communication","9798400703362","","10.1145/3615335.3623017","https://doi.org/10.1145/3615335.3623017","Social media requires that TPC researchers revisit questions of ethics and justice. Specifically, social media complicates ethical issues around representation and privacy. While representation must be localized, maintaining participant privacy can make localized representation difficult. Thus, in this paper, I outline how I navigated these ethical questions in research about an online activist campaign, #NotAgainSU. Specifically, I outline ethical complications that come up when using sentiment analysis, numerical data, and networks. I outline how I adapted, and I develop heuristic questions for future researchers.","2023","2024-07-07 16:25:37","2024-07-07 16:25:37","","96–102","","","","","","","Sigdoc '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3615335.3623017 Number of pages: 7 Place: Orlando, FL, USA","","","","ethics; methodology; social justice; social media; technical and professional communication; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"INRXBJLJ","conferencePaper","2014","Luz, Saturnino; Masoodian, Masood","Readability of a background map layer under a semi-transparent foreground layer","Proceedings of the 2014 international working conference on advanced visual interfaces","978-1-4503-2775-6","","10.1145/2598153.2598174","https://doi.org/10.1145/2598153.2598174","This study investigates the readability (interpretability) of information presented on a geographical map onto which a semi-transparent multivariate selection layer has been overlaid. The investigation is based on an information visualization prototype developed for a mobile platform (tablet devices) which aimed at supporting epidemiologists and medical staff in field data collection and epidemiological interpretation tasks. Different factors are analysed under varying transparency (alpha blending) levels, including: map interpretation task (covering ""seeing map"" and ""reading map"" tasks), legend symbol and map area type. Our results complement other studies that focused on the readability characteristics of items displayed on semi-transparent foreground layers developed in the context of ""toolglass"" interfaces. The implications of these results to the usability of transparency variable selection layers in geographical map applications are also discussed.","2014","2024-07-07 16:25:37","2024-07-07 16:25:37","","161–168","","","","","","","Avi '14","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2598153.2598174 Number of pages: 8 Place: Como, Italy","","","","epidemiology; geographical maps; information visualization; transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQFLS55W","conferencePaper","2022","Hoque, Md Naimul; Ghai, Bhavya; Elmqvist, Niklas","DramatVis personae: Visual text analytics for identifying social biases in creative writing","Proceedings of the 2022 ACM designing interactive systems conference","978-1-4503-9358-4","","10.1145/3532106.3533526","https://doi.org/10.1145/3532106.3533526","Implicit biases and stereotypes are often pervasive in different forms of creative writing such as novels, screenplays, and children’s books. To understand the kind of biases writers are concerned about and how they mitigate those in their writing, we conducted formative interviews with nine writers. The interviews suggested that despite a writer’s best interest, tracking and managing implicit biases such as a lack of agency, supporting or submissive roles, or harmful language for characters representing marginalized groups is challenging as the story becomes longer and complicated. Based on the interviews, we developed DramatVis Personae (DVP), a visual analytics tool that allows writers to assign social identities to characters, and evaluate how characters and different intersectional social identities are represented in the story. To evaluate DVP, we first conducted think-aloud sessions with three writers and found that DVP is easy-to-use, naturally integrates into the writing process, and could potentially help writers in several critical bias identification tasks. We then conducted a follow-up user study with 11 writers and found that participants could answer questions related to bias detection more efficiently using DVP in comparison to a simple text editor.","2022","2024-07-07 16:25:37","2024-07-07 16:25:37","","1260–1276","","","","","","","Dis '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3532106.3533526 Number of pages: 17 Place: Virtual Event, Australia","","","","and NLP.; bias; Creative writing; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QYVESUE3","journalArticle","2017","Faul, Franz","Toward a perceptually uniform parameter space for filter transparency","ACM Trans. Appl. Percept.","","1544-3558","10.1145/3022732","https://doi.org/10.1145/3022732","Filter models of perceptual transparency relate to regularities in the retinal projections caused by light transmitting objects like clear liquids or glass and have been found to predict the color conditions for perceptual transparency more accurately than alternative models. An important but unsolved problem is how exactly the model parameters are related to the properties of the perceived transparent layer. We previously proposed a parametrization in terms of hue, saturation, overall transmittance and clarity of the filter that seems to capture important dimensions of the phenomenal impressions. However, these parameters are not independent and the corresponding scales are not perceptually uniform. Here, an invertible transformation of this parameter space is proposed that strongly mitigates these problems. This results in a more intuitively interpretable parameter set that seems well suited for the analysis of existing stimuli and the generation of transparent overlays with predefined perceptual properties. The latter property makes it suitable for graphics and visualization applications.","2017-01","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","2","14","","","","","","","","","","","","","","","","","Citation Key: 10.1145/3022732 Number of pages: 21 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 13 tex.issue_date: April 2017","","","","Color perception; transparency perception; transparency picker; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTZPRSIW","conferencePaper","2018","Santos, Victor; Camara, Pedro; Bernardini, Flavia; Viterbo, Jose; Jorge, Douglas","A framework for constructing open data map visualizations","Proceedings of the XIV brazilian symposium on information systems","978-1-4503-6559-8","","10.1145/3229345.3229358","https://doi.org/10.1145/3229345.3229358","Open Government Data has been made available by public institutions in Brazil and the world, and can add value to various sectors of society. Open data is also linked to smart cities, and hence important in this context, as it is the first step towards public transparency. Despite the wide range of Open Government Data, interpreting such data sets is a non-trivial task, due to the massive amount of raw data. This stimulates the search for techniques and methodologies that allow the interpretation of implicit information and deduction of new knowledge. One of the approaches used for these tasks involves the use of data visualizations. In addition to data visualizations classically used in descriptive statistics for data analysis, such as line or bar charts, many web sites have been used map visualization techniques. This type of visualization is important, since visualization of georeferenced data combined with other types of information can aid its interpretation. However, for data visualization construction on maps, it is necessary that the objects to be visualized are georeferenced. There are standards for turning such data available, however they are diverse, which may make it difficult for a single tool to display views from different sources. This work aims to present a framework that defines data standards for constructing data visualizations on maps of various types. Based on this framework, a tool was implemented to facilitate the creation of different map views, both by developers of open data portals and by users who analyze such data.","2018","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","Sbsi '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3229345.3229358 Number of pages: 7 Place: Caxias do Sul, Brazil tex.articleno: 12","","","","Information Visualization in Maps; Open Government Data; Transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TWLAXGB4","conferencePaper","2010","Luboschik, Martin; Radloff, Axel; Schumann, Heidrun","A new weaving technique for handling overlapping regions","Proceedings of the international conference on advanced visual interfaces","978-1-4503-0076-6","","10.1145/1842993.1842999","https://doi.org/10.1145/1842993.1842999","The use of transparencies is a common strategy in visual representations to guarantee the visibility of different overlapping graphical objects, especially, if no visibility-deciding order is given (e.g., importance, depth). Alpha-blending, however, could generate new colors that are not specified by the given color scale and overlapping shapes may become difficult to be separated visually and the selection of specific elements would be difficult. In this paper, we present a new approach for representing overlapping regions: Instead of blending different colors, our weaving technique separates the original colors and shapes are easier to differentiate. Due to a deterministic weaving order, all overlapping objects are visible. We apply our approach to scatter plot visualizations to enhance the communication of overlapping clusters.","2010","2024-07-07 16:25:37","2024-07-07 16:25:37","","25–32","","","","","","","Avi '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1842993.1842999 Number of pages: 8 Place: Roma, Italy","","","","information visualization; interaction; overlapping; transparency; weaving","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RHDJUC4M","conferencePaper","2023","Shrestha, Hilson; Cachel, Kathleen; Alkhathlan, Mallak; Rundensteiner, Elke; Harrison, Lane","Help or hinder? Evaluating the impact of fairness metrics and algorithms in visualizations for consensus ranking","Proceedings of the 2023 ACM conference on fairness, accountability, and transparency","9798400701924","","10.1145/3593013.3594108","https://doi.org/10.1145/3593013.3594108","For applications where multiple stakeholders provide recommendations, a fair consensus ranking must not only ensure that the preferences of rankers are well represented, but must also mitigate disadvantages among socio-demographic groups in the final result. However, there is little empirical guidance on the value or challenges of visualizing and integrating fairness metrics and algorithms into human-in-the-loop systems to aid decision-makers. In this work, we design a study to analyze the effectiveness of integrating such fairness metrics-based visualization and algorithms. We explore this through a task-based crowdsourced experiment comparing an interactive visualization system for constructing consensus rankings, ConsensusFuse, with a similar system that includes visual encodings of fairness metrics and fair-rank generation algorithms, FairFuse. We analyze the measure of fairness, agreement of rankers’ decisions, and user interactions in constructing the fair consensus ranking across these two systems. In our study with 200 participants, results suggest that providing these fairness-oriented support features nudges users to align their decision with the fairness metrics while minimizing the tedious process of manually having to amend the consensus ranking. We discuss the implications of these results for the design of next-generation fairness oriented-systems and along with emerging directions for future research.","2023","2024-07-07 16:25:37","2024-07-07 16:25:37","","1685–1698","","","","","","","FAccT '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3593013.3594108 Number of pages: 14 Place: Chicago, IL, USA","","","","empirical study; fairness; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KHUP94CH","conferencePaper","2024","Marques, João Marcelo Dos Santos; Ferreira, Simone Bacellar Leal","How to promote descriptions in dynamic charts in light of transparency? A study on the accessibility barriers faced by citizens with severe visual impairment: Como promover descrições em gráficos dinâmicos à luz da transparência? Um estudo sobre as barreiras de acessibilidade enfrentadas por cidadãos com deficiência visual grave","Proceedings of the 20th brazilian symposium on information systems","9798400709968","","10.1145/3658271.3658277","https://doi.org/10.1145/3658271.3658277","Context: With the advent of digital transformation, government agencies provide Information Systems (IS) with data visualizations, including dynamic graphs. However, people with severe visual impairment still face barriers on the Web when it comes to accessing the information presented in these graphics. Problem: This part of society cannot understand the information described in these visual contents, meaning they cannot graphically construct a mental model. Solution: Recommendations for improvements grouped into four categories covering familiarity with the use of keys, web content, understanding of information, preference for descriptions encoded in two categories (captions and values; color), navigation features, ways of acquiring descriptions, dissemination of information. SI Theory: This article was conceived under the umbrella of Software Systems Theory. Method: This work is empirical in nature with a qualitative methodological approach, in which direct observation and various research strategies, techniques and analysis of results were used. Summary Results: Based on a web survey with 41 participants and a subsequent field study with the participation of 12 people with visual impairments, the demands and preferences of these citizens were determined, based on tests carried out on portals at three government levels (municipal, state and federal) and semi-structured interviews. Contributions to SI: As a contribution, this article can assist research in Information Systems aiming at describing dynamic graphics from the perspective of information transparency for the understanding of citizens with visual impairments, in addition to promoting research in HCI and related areas aligned with GranDSI-BR 2016 -2026.CCS CONCEPTS • Human-centered computing; • Accessibility; • Accessibility systems and tools","2024","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","Sbsi '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3658271.3658277 Number of pages: 10 Place: Juiz de Fora, Brazil tex.articleno: 6","","","","accessibility; data visualization; information systems; transparency; visual impairment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49F2RGYK","conferencePaper","2022","Zheng, Xinyi; Rossi, Ryan A.; Ahmed, Nesreen K.; Moritz, Dominik","Network report: a structured description for network datasets","Proceedings of the 31st ACM international conference on information &amp; knowledge management","978-1-4503-9236-5","","10.1145/3511808.3557115","https://doi.org/10.1145/3511808.3557115","The rapid development of network science and technologies depends on shareable datasets. Currently, there is no standard practice for reporting and sharing network datasets. Some network dataset providers only share links, while others provide some contexts or basic statistics. As a result, critical information may be unintentionally dropped, and network dataset consumers may misunderstand or overlook critical aspects. Inappropriately using a network dataset can lead to severe consequences (e.g., discrimination) especially when machine learning models on networks are deployed in high-stake domains. Challenges arise as networks are often used across different domains (e.g., network science, physics, etc) and have complex structures. To facilitate the communication between network dataset providers and consumers, we propose network report. A network report is a structured description that summarizes and contextualizes a network dataset. Network report extends the idea of dataset reports (e.g., Datasheets for Datasets) from prior work with network-specific descriptions of the non-i.i.d. nature, demographic information, network characteristics, etc. We hope network reports encourage transparency and accountability in network research and development across different fields.","2022","2024-07-07 16:25:37","2024-07-07 16:25:37","","3694–3704","","","","","","","Cikm '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3511808.3557115 Number of pages: 11 Place: Atlanta, GA, USA","","","","fairness; graph; machine learning; network; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQ9L8P5B","conferencePaper","2018","Degbelo, Auriol; Kauppinen, Tomi","Increasing transparency through web maps","Companion proceedings of the the web conference 2018","978-1-4503-5640-4","","10.1145/3184558.3191515","https://doi.org/10.1145/3184558.3191515","Recent years have witnessed progress of public institutions in making their datasets available online, free of charge, for re-use. This notwithstanding, there is still a long way to go to put the power of data in the hands of citizens. This article suggests that transparency in the context of open government can be increased through web maps featuring: i) Application Programming Interfaces (APIs) which support app and data usage tracking; and (ii) 'transparency badges' which inform the users about the presence/absence of extra, useful contextual information. Eight examples of web maps are introduced as proof of concept for the idea. Designing and implementing these web maps has reminded of the need of interactive guidelines to help non-experts select vocabularies, and datasets to link to. The ideas presented are relevant to making existing open data more user friendly (and ultimately more usable).","2018","2024-07-07 16:25:37","2024-07-07 16:25:37","","899–904","","","","","","","Www '18","","","","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","","","","","","","","Citation Key: 10.1145/3184558.3191515 Number of pages: 6 Place: Lyon, France","","","","cartographic interaction primitives; linked data visualization; open geodata; transparency; visual variables; web maps","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KQQ8D69A","conferencePaper","2002","Trembilski, Andrzej; Broßler, Andreas","Transparency for polygon based cloud rendering","Proceedings of the 2002 ACM symposium on applied computing","1-58113-445-2","","10.1145/508791.508943","https://doi.org/10.1145/508791.508943","For the local TV presentation of weather forecast data it is important to have high-quality and fast visualisation of clouds. In this paper we present surface-based transparency computation methods for the high performance visualisation of clouds from data produced by a routine meteorological weather simulation. In contrast to the state-of-the-art volume cloud visualisation we use only hardware-supported polygon-based transparency computation.","2002","2024-07-07 16:25:37","2024-07-07 16:25:37","","785–790","","","","","","","Sac '02","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/508791.508943 Number of pages: 6 Place: Madrid, Spain","","","","cloud modelling and visualisation; meteorological visualisation; transparency computation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IIIAETDP","conferencePaper","2023","Marques, João Marcelo dos Santos; Ferreira, Simone Bacellar Leal","Description of dynamic images: a systematic mapping for the understanding and transparency of information that may be perceptible visually impaired citizens","Proceedings of the XIX brazilian symposium on information systems","9798400707599","","10.1145/3592813.3592910","https://doi.org/10.1145/3592813.3592910","Context: With the advent of the Web and the advancement of information and communication technologies (ICTs), society began to keep itself informed of facts and everyday events and can be connected anywhere on the planet. However, a portion of society, such as the visually impaired, still face major challenges in Information Systems (IS) on the Web regarding access to information in dynamic images. Problem: These citizens, in general, cannot understand the information described in these images, so that they can build a mental model. You need to provide alternative ways of describing them. Solution: In this article, studies were explored that could help in the description of dynamic images under the pillars of understanding, transparency of information and perception for the construction of SIs for the visually impaired. SI theory: This work follows the protocols adopted for systematic mapping directed to meta-analysis and hermeneutics. Method: A Systematic Mapping of the Literature was used following the steps of planning, conducting and analyzing the results. Summary Results: From the search repositories, 1019 studies were captured. After applying the evaluation criteria, 11 relevant studies were accepted. The results revealed that there are few studies in the development of technologies that use methods, models and techniques for the description of dynamic images. Contributions to IS: As a contribution, this work exposes research gaps for the creation of ISs that include descriptions in dynamic images for the understanding and transparency of perceptible information to people with visual impairments. In addition to instigating research in Human-Computer Interaction aligned with the GranDSI-BR 2016-2026.","2023","2024-07-07 16:25:37","2024-07-07 16:25:37","","229–236","","","","","","","Sbsi '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3592813.3592910 Number of pages: 8 Place: Maceió, Brazil","","","","accessibility; data visualization; information systems; systematic mapping of the literature; transparency; visual impairment","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPDDY3RJ","journalArticle","2020","Gaie, Christophe","Providing detailed information on national policies to cope with the covid-19 pandemic","Digit. Gov.: Res. Pract.","","","10.1145/3428089","https://doi.org/10.1145/3428089","This article considers the valorization of government interventions to support the economy in France; in particular, it provides a detailed geovisualization of emergency funds granted to companies. Transparency of the actions performed to cope with the pandemic situation is offered by the combination of open data and the usage of a new open-source visualization framework. It provides the essential information of public policies for citizens, academics, companies, public decision makers, and so on. The proposed framework is completely customizable and may be easily re-used in many crisis management situations, such as hurricanes, earthquakes, flooding, nuclear disasters.","2020-11","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","1","2","","","","","","","","","","","","","","","","","Citation Key: 10.1145/3428089 Number of pages: 11 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 7 tex.issue_date: January 2021","","","","economic subsidies; government intervention; open data; Open government; open-source algorithms; public policies; subsidies; transparency; visualization framework","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"83293HLI","conferencePaper","2024","Krop, Philipp; Koch, Martin Jakobus; Carolus, Astrid; Latoschik, Marc Erich; Wienrich, Carolin","The effects of expertise, humanness, and congruence on perceived trust, warmth, competence and intention to use embodied AI","Extended abstracts of the 2024 CHI conference on human factors in computing systems","9798400703317","","10.1145/3613905.3650749","https://doi.org/10.1145/3613905.3650749","Even though people imagine different embodiments when asked which AI they would like to work with, most studies investigate trust in AI systems without specific physical appearances. This study aims to close this gap by combining influencing factors of trust to analyze their impact on the perceived trustworthiness, warmth, and competence of an embodied AI. We recruited 68 participants who observed three co-working scenes with an embodied AI, presented as expert/novice (expertise), human/AI (humanness), or congruent/slightly incongruent to the environment (congruence). Our results show that the expertise condition had the largest impact on trust, acceptance, and perceived warmth and competence. When controlled for perceived competence, the humanness of the AI and the congruence of its embodiment to the environment also influence acceptance. The results show that besides expertise and the perceived competence of the AI, other design variables are relevant for successful human-AI interaction, especially when the AI is embodied.","2024","2024-07-07 16:25:37","2024-07-07 16:25:37","","","","","","","","","Chi ea '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3613905.3650749 Number of pages: 9 tex.articleno: 316","","","","Congruence; Framing; Intelligent Agents; Technology Acceptance; Trust; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJYTI3ZS","conferencePaper","2008","Kittur, Aniket; Suh, Bongwon; Chi, Ed H.","Can you ever trust a wiki? impacting perceived trustworthiness in wikipedia","Proceedings of the 2008 ACM conference on computer supported cooperative work","978-1-60558-007-4","","10.1145/1460563.1460639","https://doi.org/10.1145/1460563.1460639","Wikipedia has become one of the most important information resources on the Web by promoting peer collaboration and enabling virtually anyone to edit anything. However, this mutability also leads many to distrust it as a reliable source of information. Although there have been many attempts at developing metrics to help users judge the trustworthiness of content, it is unknown how much impact such measures can have on a system that is perceived as inherently unstable. Here we examine whether a visualization that exposes hidden article information can impact readers' perceptions of trustworthiness in a wiki environment. Our results suggest that surfacing information relevant to the stability of the article and the patterns of editor behavior can have a significant impact on users' trust across a variety of page types.","2008","2024-07-07 16:25:37","2024-07-07 16:25:37","","477–480","","","","","","","Cscw '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1460563.1460639 Number of pages: 4 Place: San Diego, CA, USA","","","","collaboration; social computing; stability; trust; visualization; wiki; wikipedia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6ZQGEBP2","conferencePaper","2013","Matuszak, William J.; DiPippo, Lisa; Sun, Yan Lindsay","CyberSAVe: situational awareness visualization for cyber security of smart grid systems","Proceedings of the tenth workshop on visualization for cyber security","978-1-4503-2173-0","","10.1145/2517957.2517961","https://doi.org/10.1145/2517957.2517961","We offer algorithms and visualization techniques for cyber trust in a Smart Grid system. Cyber trust is evaluated in terms of a mathematical model consisting of availability, detection and false alarm trust values, as well as a model of predictability. We develop a prototype Cyber Situational Awareness Visualization (CyberSAVe) tool to visualize cyber trust. We provide Operational Decision Aids (ODAs) displayed in context with a SCADA management information. We define cyber trust metrics, which are calculated and displayed in real-time in the Metric Assessment System (MAS) of CyberSAVe. We demonstrate the use of trust combined with visualization of trust to detect various types of attacks on the Smart Grid.","2013","2024-07-07 16:25:37","2024-07-07 16:25:37","","25–32","","","","","","","VizSec '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2517957.2517961 Number of pages: 8 Place: Atlanta, Georgia, USA","","","","cyber security; framework; situational awareness; smart grid; trust; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CK7CZVNA","conferencePaper","2019","Soroko, Daria; Döge, Nina; Al-Shafeei, Ahmed; Heuer, Hendrik","Unpacking a model: An interactive visualization of a text similarity algorithm for legal documents","Proceedings of mensch und computer 2019","978-1-4503-7198-8","","10.1145/3340764.3345371","https://doi.org/10.1145/3340764.3345371","This paper presents a functional prototype for an interactive web-based interface i_sift developed to foreground the decision-making process of an algorithm that detects similarities in legal texts through word embeddings. Using this as a case study in computational social science, our goal is, first, to highlight the importance of making computational tools and methods transparent to social scientists. Secondly, we suggest an approach that accomplishes this using methods and principles from interactive machine learning and the algorithmic experience framework.","2019","2024-07-07 16:25:37","2024-07-07 16:25:37","","875–879","","","","","","","MuC '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3340764.3345371 Number of pages: 5 Place: Hamburg, Germany","","","","algorithmic experience; algorithmic transparency; computational social science; explanation interface; interactive machine learning; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"82ZYBJ9W","conferencePaper","2022","Johnson, Brittany; Brun, Yuriy","Fairkit-learn: a fairness evaluation and comparison toolkit","Proceedings of the ACM/IEEE 44th international conference on software engineering: Companion proceedings","978-1-4503-9223-5","","10.1145/3510454.3516830","https://doi.org/10.1145/3510454.3516830","Advances in how we build and use software, specifically the integration of machine learning for decision making, have led to widespread concern around model and software fairness. We present fairkit-learn, an interactive Python toolkit designed to support data scientists' ability to reason about and understand model fairness. We outline how fairkit-learn can support model training, evaluation, and comparison and describe the potential benefit that comes with using fairkit-learn in comparison to the state-of-the-art. Fairkit-learn is open source at https://go.gmu.edu/fairkit-learn/.","2022","2024-07-07 16:25:38","2024-07-07 16:25:38","","70–74","","","","","","","Icse '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3510454.3516830 Number of pages: 5 Place: Pittsburgh, Pennsylvania","","","","bias-free software design; software fairness; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F4JVID3K","conferencePaper","2022","Ooge, Jeroen; Verbert, Katrien","Explaining artificial intelligence with tailored interactive visualisations","Companion proceedings of the 27th international conference on intelligent user interfaces","978-1-4503-9145-0","","10.1145/3490100.3516481","https://doi.org/10.1145/3490100.3516481","Artificial intelligence (AI) is becoming ubiquitous in the lives of both researchers and non-researchers, but AI models often lack transparency. To make well-informed and trustworthy decisions based on these models, people require explanations that indicate how to interpret the model outcomes. This paper presents our ongoing research in explainable AI, which investigates how visual analytics interfaces and visual explanations, tailored to the target audience and application domain, can make AI models more transparent and allow interactive steering based on domain expertise. First, we present our research questions and methods, contextualised by related work at the intersection of AI, human-computer interaction, and information visualisation. Then, we discuss our work so far in healthcare, agriculture, and education. Finally, we share our research ideas for additional studies in these domains.","2022","2024-07-07 16:25:38","2024-07-07 16:25:38","","120–123","","","","","","","IUI '22 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3490100.3516481 Number of pages: 4 Place: Helsinki, Finland","","","","algorithmic transparency; explainability; information visualisation; interpretability; XAI","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9R8CZSD","conferencePaper","2022","Doan, Xengie; Selzer, Annika; Rossi, Arianna; Botes, Wilhelmina Maria; Lenzini, Gabriele","Context, prioritization, and unexpectedness: Factors influencing user attitudes about infographic and comic consent","Companion proceedings of the web conference 2022","978-1-4503-9130-6","","10.1145/3487553.3524632","https://doi.org/10.1145/3487553.3524632","Being asked to agree to data disclosure is a ubiquitous experience in digital services - yet it is rare to encounter a well-designed consent experience. Considering the momentum for a European data space where personal information easily flows across organizations, sectors, and nations, solving the thorny issue of ”how to get consent right” cannot be postponed any further. In this paper, we describe the first findings from a study based on 24 semi-structured interviews investigating participants’ expectations and opinions toward a consent form redesigned as a comic and an infographic in a data-sharing scenario. We found that time, information prioritization, tone, and audience fit are crucial when individuals are invited to disclose their information and the infographic is a better fit in biomedical scenarios.","2022","2024-07-07 16:25:38","2024-07-07 16:25:38","","534–545","","","","","","","Www '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3487553.3524632 Number of pages: 12 Place: Virtual Event, Lyon, France","","","","comics; consent UX; data governance; health data sharing; transparency; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AQ7PAG9E","conferencePaper","2024","Wang, Zezhong; Hao, Shan; Carpendale, Sheelagh","Card-based approach to engage exploring ethics in AI for data visualization","Extended abstracts of the 2024 CHI conference on human factors in computing systems","9798400703317","","10.1145/3613905.3650972","https://doi.org/10.1145/3613905.3650972","We present AI-VIS EthiCards, a card-based approach to explore ethics tailored for AI for visualization. The continuous integration of artificial intelligence and data visualization has brought about increased efficiency and benefits, yet inevitably raises ethical concerns. The emerging field of AI for visualization is marked by its inherent complexity, making it crucial for researchers, designers, and practitioners to cultivate ethical literacy and contemplate moral obligations within this intricate environment. These cards aim to aid users in learning, discussing, and reflecting on the ethical dilemmas that may arise from the integration of AI technology and visualization. The AI-VIS EthiCard set contains six themes: Goals, AI-VIS Tasks, Technologies, Ethical Principles, People-In-Focus, and Challenges, proposes various modes of use, including theoretical exploration, and design development simulations, with five activities. We aim to offer users an exploratory and open approach to discussions, providing multiple perspectives to guide ethical considerations when applying AI for visualization. The full set of cards is available at https://aivisethicards.github.io/.","2024","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Chi ea '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3613905.3650972 Number of pages: 7 tex.articleno: 69","","","","Artificial intelligence; Card; Data visualization; Education; Ethics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FF7SJWZF","conferencePaper","2020","Lauer, Claire; O'Brien, Shaun","The deceptive potential of common design tactics used in data visualizations","Proceedings of the 38th ACM international conference on design of communication","978-1-4503-7525-2","","10.1145/3380851.3416762","https://doi.org/10.1145/3380851.3416762","Visualizations effectively communicate data about important political, social, environmental, and health topics to a wide range of audiences; however, longstanding trust of graphs as conveyors of factual data makes them an easy means for spreading misinformation. Scholars in technical and professional communication have not yet conducted needed empirical research into people's perception and comprehension of data visualizations, especially when part of larger information texts [1]. Our study investigated the extent to which people exaggerated the differences between data points when reading graphs about non-controversial topics that used deceptive techniques and/or exaggerated titles. Participants (n=329) were randomly assigned to view one of four treatments for four different graph types (bar, line, pie, and bubble) and then asked to answer a question about each graph. Results show that deceptive techniques used in the graphs (including truncated axes, 3-D exaggeration, and arbitrary sizing), caused participants to misinterpret information in the deceptive vs. control visualizations for all of the graphs regardless of graph type, previous visualization coursework or comfort level with reading graphs. Results also showed that the presence of exaggerated vs. control titles that accompanied each graph did not significantly influence the extent of the misinterpretation. We will discuss the implication of these findings for technical communication as well as avenues of future research already underway that investigate these topics further.","2020","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Sigdoc '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3380851.3416762 Number of pages: 9 Place: Denton, TX, USA tex.articleno: 27","","","","Data Visualization; Deceptive tactics; Ethics; Graphs; Titles; Truncated Axis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFFMTLR7","conferencePaper","2019","Lim, Brian; Sarkar, Advait; Smith-Renner, Alison; Stumpf, Simone","ExSS: explainable smart systems 2019","Companion proceedings of the 24th international conference on intelligent user interfaces","978-1-4503-6673-1","","10.1145/3308557.3313112","https://doi.org/10.1145/3308557.3313112","Smart systems that apply complex reasoning to make decisions and plan behavior are often difficult for users to understand. While research to make systems more explainable and therefore more intelligible and transparent is gaining pace, there are numerous issues and problems regarding these systems that demand further attention. The ExSS 2019 workshop is a follow-on from the very successful ExSS 2018 workshop previously held at IUI, to bring academia and industry together to address these issues. This workshop includes a keynote, paper panels, poster session, and group activities, with the goal of developing concrete approaches to handling challenges related to the design and development of explainable smart systems.","2019","2024-07-07 16:25:38","2024-07-07 16:25:38","","125–126","","","","","","","IUI '19 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3308557.3313112 Number of pages: 2 Place: Marina del Ray, California","","","","explanations; intelligent systems; intelligibility; machine learning; transparency; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YYAXQTJ","conferencePaper","2023","Büschel, Wolfgang; Krug, Katja; Klamka, Konstantin; Dachselt, Raimund","Demonstrating CleAR sight: Transparent interaction panels for augmented reality","Extended abstracts of the 2023 CHI conference on human factors in computing systems","978-1-4503-9422-2","","10.1145/3544549.3583891","https://doi.org/10.1145/3544549.3583891","In this work, we demonstrate our concepts for transparent interaction panels in augmented-reality environments. Mobile devices can support interaction with head-mounted displays by providing additional input channels, such as touch &amp; pen input and spatial device input, and also an additional, personal display. However, occlusion of the physical context, other people, or the virtual content can be problematic. To address this, we previously introduced CleAR Sight, a concept and research platform for transparent interaction panels to support interaction in HMD-based mixed reality. Here, we will demonstrate the different interaction and visualization techniques supported in CleAR Sight that facilitate basic manipulation, data exploration, and sketching &amp; annotation for various use cases such as 3D volume visualization, collaborative data analysis, and smart home control.","2023","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Chi ea '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3544549.3583891 Number of pages: 5 Place: Hamburg, Germany tex.articleno: 432","","","","augmented reality; human-computer interaction; transparent displays; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XZF8NRAL","conferencePaper","2018","Kong, Ha-Kyung; Liu, Zhicheng; Karahalios, Karrie","Frames and slants in titles of visualizations on controversial topics","Proceedings of the 2018 CHI conference on human factors in computing systems","978-1-4503-5620-6","","10.1145/3173574.3174012","https://doi.org/10.1145/3173574.3174012","Slanted framing in news article titles induce bias and influence recall. While recent studies found that viewers focus extensively on titles when reading visualizations, the impact of titles in visualization remains underexplored. We study frames in visualization titles, and how the slanted framing of titles and the viewer's pre-existing attitude impact recall, perception of bias, and change of attitude. When asked to compose visualization titles, people used five existing news frames, an open-ended frame, and a statistics frame. We found that the slant of the title influenced the perceived main message of a visualization, with viewers deriving opposing messages from the same visualization. The results did not show any significant effect on attitude change. We highlight the danger of subtle statistics frames and viewers' unwarranted conviction of the neutrality of visualizations. Finally, we present a design implication for the generation of visualization titles and one for the viewing of titles.","2018","2024-07-07 16:25:38","2024-07-07 16:25:38","","1–12","","","","","","","Chi '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3173574.3174012 Number of pages: 12 Place: Montreal QC, Canada","","","","attitude change; bias; data visualization; frames; visualization title","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QD8XFX34","conferencePaper","2018","O'Brien, Shaun; Lauer, Claire","Testing the susceptibility of users to deceptive data visualizations when paired with explanatory text","Proceedings of the 36th ACM international conference on the design of communication","978-1-4503-5935-1","","10.1145/3233756.3233961","https://doi.org/10.1145/3233756.3233961","In this paper we present the results of an empirical study that analyzed how people understand the data presented to them in deceptive data visualizations when those visualizations are paired with non-deceptive text. This study was administered as an online user survey and was designed to test the extent to which deceptive data visualizations can fool users, even when they are accompanied by a paragraph of accurate text. The study consisted of a basic demographic questionnaire, chart familiarity assessment, and data visualization survey. A total of 256 participants completed the survey and were evenly distributed between a control (non-deceptive) survey and a test (deceptive) survey in which participants were asked to observe a paragraph of text and a data visualization. Participants then answered a question relevant to the observed information to measure how they perceived the information. The results of the study confirmed that deceptive techniques in data visualizations caused participants to misinterpret the information in the deceptive data visualizations even when they were accompanied by accurate explanatory text. Furthermore, certain demographics and comfort levels with chart types were more susceptible to certain types of deceptive techniques. These results highlight the importance of education and awareness in the area of data visualizations to ensure deceptive practices are not utilized on the part of developers and to avoid misinformation on the part of users.","2018","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Sigdoc '18","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3233756.3233961 Number of pages: 8 Place: Milwaukee, WI, USA tex.articleno: 7","","","","ACM Proceedings; communication; Data Visualization; design; Ethics; Infographic; research; Visual Rhetoric","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W3LZRMTM","conferencePaper","2018","Cooney, Martin; Pashami, Sepideh; Sant'Anna, Anita; Fan, Yuantao; Nowaczyk, Slawomir","Pitfalls of Affective Computing: How can the automatic visual communication of emotions lead to harm, and what can be done to mitigate such risks","Companion proceedings of the the web conference 2018","978-1-4503-5640-4","","10.1145/3184558.3191611","https://doi.org/10.1145/3184558.3191611","What would happen in a world where people could ""see” others' hidden emotions directly through some visualizing technology Would lies become uncommon and would we understand each other better Or to the contrary, would such forced honesty make it impossible for a society to exist The science fiction television show Black Mirror has exposed a number of darker scenarios in which such futuristic technologies, by blurring the lines of what is private and what is not, could also catalyze suffering. Thus, the current paper first turns an eye towards identifying some potential pitfalls in emotion visualization which could lead to psychological or physical harm, miscommunication, and disempowerment. Then, some countermeasures are proposed and discussed–including some level of control over what is visualized and provision of suitably rich emotional information comprising intentions–toward facilitating a future in which emotion visualization could contribute toward people's well-being. The scenarios presented here are not limited to web technologies, since one typically thinks about emotion recognition primarily in the context of direct contact. However, as interfaces develop beyond today's keyboard and monitor, more information becomes available also at a distance–for example, speech-to-text software could evolve to annotate any dictated text with a speaker's emotional state.","2018","2024-07-07 16:25:38","2024-07-07 16:25:38","","1563–1566","","","","","","","Www '18","","","","International World Wide Web Conferences Steering Committee","Republic and Canton of Geneva, CHE","","","","","","","","Citation Key: 10.1145/3184558.3191611 Number of pages: 4 Place: Lyon, France","","","","affective computing; black mirror; emotion visualization; ethics; intention recognition; privacy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AH4LJG3B","conferencePaper","2022","Xiong, Cindy; Sarvghad, Ali; Goldstein, Daniel G; Hofman, Jake M; Demiralp, Çagatay","Investigating perceptual biases in icon arrays","Proceedings of the 2022 CHI conference on human factors in computing systems","978-1-4503-9157-3","","10.1145/3491102.3501874","https://doi.org/10.1145/3491102.3501874","Icon arrays are graphical displays in which a subset of identical shapes are filled to convey probabilities. They are widely used for communicating probabilities to the general public. A primary design decision concerning icon arrays is how to fill and arrange these shapes. For example, a designer could fill the shapes from top to bottom or in a random fashion. We investigated the effect of different arrangements in icon arrays on probability perception. We showed participants icon arrays depicting probabilities between 0","2022","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Chi '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3491102.3501874 Number of pages: 12 Place: New Orleans, LA, USA tex.articleno: 137","","","","Bias; Communication; Crowdsourcing; Icon Arrays; Perception; Proportions; Risk Visualization; Visualization of Probabilities","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7Y6RWQ9B","conferencePaper","2023","Guesmi, Mouadh; Siepmann, Clara; Chatti, Mohamed Amine; Joarder, Shoeb; Ain, Qurat Ul; Alatrash, Rawaa","Validation of the EDUSS framework for self-actualization based on transparent user models: a qualitative study","Adjunct proceedings of the 31st ACM conference on user modeling, adaptation and personalization","978-1-4503-9891-6","","10.1145/3563359.3597379","https://doi.org/10.1145/3563359.3597379","Self-actualization is the process of striving toward full potential and achieving higher goals in one’s life. Originally studied in psychology, this concept has been adopted by various disciplines, including recommender systems, as a means of addressing issues like the filter bubble problem and promoting transparency. In an earlier work, we developed a theoretically-sound framework named EDUSS to systematically design interactive visualizations of transparent user models for self-actualization. We aim in this paper to validate the effectiveness of using the EDUSS framework to support self-actualization. To this end, we implemented interactive visualizations of transparent user interest models designed with the help of the EDUSS framework into the transparent Recommendation and Interest Modeling Application (RIMA). Further, we conducted a qualitative user study (N=10) to investigate the effect of these visualizations in supporting users to achieve self-actualization. Our study showed qualitative evidence validating that applying the EDUSS framework to design systems for self-actualization has the potential to help users reach self-actualization goals to a certain extent.","2023","2024-07-07 16:25:38","2024-07-07 16:25:38","","229–238","","","","","","","UMAP '23 adjunct","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3563359.3597379 Number of pages: 10 Place: Limassol, Cyprus","","","","Explainable User Models; Recommender Systems; Self-actualization; Transparent User Models; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ERT9MZQT","conferencePaper","1997","Interrante, Victoria","Illustrating surface shape in volume data via principal direction-driven 3D line integral convolution","Proceedings of the 24th annual conference on computer graphics and interactive techniques","0-89791-896-7","","10.1145/258734.258796","https://doi.org/10.1145/258734.258796","","1997","2024-07-07 16:25:38","2024-07-07 16:25:38","","109–116","","","","","","","Siggraph '97","","","","ACM Press/Addison-Wesley Publishing Co.","USA","","","","","","","","Citation Key: 10.1145/258734.258796 Number of pages: 8","","","","isosurfaces; line integral convolution; principal directions; shape representation; solid texture; stroke textures; transparent surfaces; visualization; volume rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7262I96F","conferencePaper","2020","Wexler, James; Pushkarna, Mahima; Robinson, Sara; Bolukbasi, Tolga; Zaldivar, Andrew","Probing ML models for fairness with the what-if tool and SHAP: hands-on tutorial","Proceedings of the 2020 conference on fairness, accountability, and transparency","978-1-4503-6936-7","","10.1145/3351095.3375662","https://doi.org/10.1145/3351095.3375662","As more and more industries use machine learning, it's important to understand how these models make predictions, and where bias can be introduced in the process. In this tutorial we'll walk through two open source frameworks for analyzing your models from a fairness perspective. We'll start with the What-If Tool, a visualization tool that you can run inside a Python notebook to analyze an ML model. With the What-If Tool, you can identify dataset imbalances, see how individual features impact your model's prediction through partial dependence plots, and analyze human-centered ML models from a fairness perspective using various optimization strategies.Then we'll look at SHAP, a tool for interpreting the output of any machine learning model, and seeing how a model arrived at predictions for individual datapoints. We will then show how to use SHAP and the What-If Tool together. After the tutorial you'll have the skills to get started with both of these tools on your own datasets, and be better equipped to analyze your models from a fairness perspective.","2020","2024-07-07 16:25:38","2024-07-07 16:25:38","","705","","","","","","","Fat* '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3351095.3375662 Number of pages: 1 Place: Barcelona, Spain","","","","data visualization; fairness; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FALBTNCU","conferencePaper","2023","Reid, Kathy; Williams, Elizabeth T.","Common Voice and accent choice: data contributors self-describe their spoken accents in diverse ways","Proceedings of the 3rd ACM conference on equity and access in algorithms, mechanisms, and optimization","9798400703812","","10.1145/3617694.3623258","https://doi.org/10.1145/3617694.3623258","The use of machine learning (ML)-powered speech technologies has increased significantly in recent years&nbsp;[40, 56, 72]. The datasets used for training speech models often represent demographic features of the speaker – such as gender, age, and accent. These axes are frequently used to evaluate the training set and model for bias&nbsp;[52]. Here, we focus on how accent is represented in voice data due to the adverse consequences of accent bias. We perform document analysis on several voice datasets to identify how accents are currently represented. We then analyse and visualise speaker-described accents from Mozilla’s Common Voice (CV) v13 English dataset, forming an emergent taxonomy of accent descriptors. We repeat this process using the CV v13 Kiswahili dataset, demonstrating that the taxonomy has use beyond English. We find that accents are currently represented in ways that are geographically, and predominantly, nationally bound. While this pattern is also shown in speaker-described accents from CV, a more diverse set of descriptors is revealed. This work provides some early evidence for re-thinking how accents are represented in datasets intended for ML applications. Our tooling is open-sourced, and we invite further work that uses our taxonomy to assess accent bias in speech data and models.","2023","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Eaamo '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3617694.3623258 Number of pages: 10 Place: Boston, MA, USA tex.articleno: 35","","","","accent bias; accent data; accent recognition; bias; bias corpora; data visualization; dataset documentation; datasets; metadata; speech data; voice data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACANDWHX","conferencePaper","2021","Giannopoulos, Giorgos; Papastefanatos, George; Sacharidis, Dimitris; Stefanidis, Kostas","Interactivity, fairness and explanations in recommendations","Adjunct proceedings of the 29th ACM conference on user modeling, adaptation and personalization","978-1-4503-8367-7","","10.1145/3450614.3462238","https://doi.org/10.1145/3450614.3462238","More and more aspects of our everyday lives are influenced by automated decisions made by systems that statistically analyze traces of our activities. It is thus natural to question whether such systems are trustworthy, particularly given the opaqueness and complexity of their internal workings. In this paper, we present our ongoing work towards a framework that aims to increase trust in machine-generated recommendations by combining ideas from three separate recent research directions, namely explainability, fairness and user interactive visualization. The goal is to enable different stakeholders, with potentially varying levels of background and diverse needs, to query, understand, and fix sources of distrust.","2021","2024-07-07 16:25:38","2024-07-07 16:25:38","","157–161","","","","","","","Umap '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3450614.3462238 Number of pages: 5 Place: Utrecht, Netherlands","","","","explainability; fairness; interactive visualization; Recommender systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W37WVNCG","conferencePaper","2011","Assogba, Yannick; Ros, Irene; DiMicco, Joan; McKeon, Matt","Many bills: engaging citizens through visualizations of congressional legislation","Proceedings of the SIGCHI conference on human factors in computing systems","978-1-4503-0228-9","","10.1145/1978942.1979004","https://doi.org/10.1145/1978942.1979004","US federal legislation is a common subject of discussion and advocacy on the web, inspired by the open government movement. While the contents of these bills are freely available for download, understanding them is a significant challenge to experts and average citizens alike due to their length, complex language, and obscure topics. To make these important documents more accessible to the general public, we present Many Bills (http://manybills.us): a web-based set of visualization tools that reveals the underlying semantics of a bill. Using machine learning techniques, we classify each bill's sections based on existing document-level categories. We then visualize the resulting topic substructure of these bills. These visualizations provide an overview-and-detail view of bills, enabling users to read individual sections of a bill and compare topic patterns across multiple bills. Through an overview of the site's user activity and interviews with active users, this paper highlights how Many Bills makes the tasks of reading bills, identifying outlier sections in bills, and understanding congressperson's legislative activity more manageable.","2011","2024-07-07 16:25:38","2024-07-07 16:25:38","","433–442","","","","","","","Chi '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1978942.1979004 Number of pages: 10 Place: Vancouver, BC, Canada","","","","government; government transparency; information visualization; legislation; text classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RVFB9FDU","conferencePaper","2012","Gali, Guia; Oliver, Symon; Chevalier, Fanny; Diamond, Sara","Visualizing sentiments in business-customer relations with metaphors","CHI '12 extended abstracts on human factors in computing systems","978-1-4503-1016-1","","10.1145/2212776.2223661","https://doi.org/10.1145/2212776.2223661","This project explores how the visualization of sentiments, extracted from social media posts, can foster transparency and strengthen relations between businesses and their customers. Guided by the nature of the data and an iterative design based on our end users' feedback, we examine a variety of visualization styles and metaphors as possible directions for a common set of tools to benefit both groups of users.","2012","2024-07-07 16:25:38","2024-07-07 16:25:38","","1493–1498","","","","","","","Chi ea '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2212776.2223661 Number of pages: 6 Place: Austin, Texas, USA","","","","data visualization; metaphors; social media; trust","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SL2G3VMW","conferencePaper","2013","Helldin, Tove; Falkman, Göran; Riveiro, Maria; Davidsson, Staffan","Presenting system uncertainty in automotive UIs for supporting trust calibration in autonomous driving","Proceedings of the 5th international conference on automotive user interfaces and interactive vehicular applications","978-1-4503-2478-6","","10.1145/2516540.2516554","https://doi.org/10.1145/2516540.2516554","To investigate the impact of visualizing car uncertainty on drivers' trust during an automated driving scenario, a simulator study was conducted. A between-group design experiment with 59 Swedish drivers was carried out where a continuous representation of the uncertainty of the car's ability to autonomously drive during snow conditions was displayed to one of the groups, whereas omitted for the control group. The results show that, on average, the group of drivers who were provided with the uncertainty representation took control of the car faster when needed, while they were, at the same time, the ones who spent more time looking at other things than on the road ahead. Thus, drivers provided with the uncertainty information could, to a higher degree, perform tasks other than driving without compromising with driving safety. The analysis of trust shows that the participants who were provided with the uncertainty information trusted the automated system less than those who did not receive such information, which indicates a more proper trust calibration than in the control group.","2013","2024-07-07 16:25:38","2024-07-07 16:25:38","","210–217","","","","","","","AutomotiveUI '13","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2516540.2516554 Number of pages: 8 Place: Eindhoven, Netherlands","","","","acceptance; automation; driving; trust; uncertainty visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BGJGYDJ8","conferencePaper","2008","King, Jeff; Stoll, Jennifer; Hunter, Michael T.; Ahamad, Mustaque","ALPACA: a lightweight platform for analyzing claim acceptability","Proceedings of the 2nd ACM workshop on information credibility on the web","978-1-60558-259-7","","10.1145/1458527.1458540","https://doi.org/10.1145/1458527.1458540","Internet users face challenges in evaluating the validity of online information. Such evaluation is not adequately supported by current tools; we outline some of the shortcomings of these tools, including centralization, lack of automation, and lack of user-centrism. We propose a set of design principles to mitigate these shortcomings and introduce ALPACA, A Lightweight Platform for Analyzing Claim Acceptability, which adheres to these design principles. ALPACA provides a graphical means of organizing the user's trust with regard to information claims and sources, as well as tools for examining the trust assumptions of others.","2008","2024-07-07 16:25:38","2024-07-07 16:25:38","","47–52","","","","","","","Wicow '08","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1458527.1458540 Number of pages: 6 Place: Napa Valley, California, USA","","","","credibility; data visualization; internet; trust; validity","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"64LNKJXU","conferencePaper","2023","Verma, Arnav; Morais, Luiz; Dragicevic, Pierre; Chevalier, Fanny","Designing resource allocation tools to promote fair allocation: Do visualization and information framing matter?","Proceedings of the 2023 CHI conference on human factors in computing systems","978-1-4503-9421-5","","10.1145/3544548.3580739","https://doi.org/10.1145/3544548.3580739","Studies on human decision-making focused on humanitarian aid have found that cognitive biases can hinder the fair allocation of resources. However, few HCI and Information Visualization studies have explored ways to overcome those cognitive biases. This work investigates whether the design of interactive resource allocation tools can help to promote allocation fairness. We specifically study the effect of presentation format (using text or visualization) and a specific framing strategy (showing resources allocated to groups or individuals). In our three crowdsourced experiments, we provided different tool designs to split money between two fictional programs that benefit two distinct communities. Our main finding indicates that individual-framed visualizations and text may be able to curb unfair allocations caused by group-framed designs. This work opens new perspectives that can motivate research on how interactive tools and visualizations can be engineered to combat cognitive biases that lead to inequitable decisions.","2023","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Chi '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3544548.3580739 Number of pages: 16 Place: Hamburg, Germany tex.articleno: 838","","","","cognitive bias; donation; framing; resource allocation; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5I63ELPA","conferencePaper","2024","Yang, Fumeng; Mortenson, Chloe Rose; Nisbet, Erik; Diakopoulos, Nicholas; Kay, Matthew","In dice we trust: Uncertainty displays for maintaining trust in election forecasts over time","Proceedings of the CHI conference on human factors in computing systems","9798400703300","","10.1145/3613904.3642371","https://doi.org/10.1145/3613904.3642371","Trust in high-profile election forecasts influences the public’s confidence in democratic processes and electoral integrity. Yet, maintaining trust after unexpected outcomes like the 2016 U.S. presidential election is a significant challenge. Our work confronts this challenge through three experiments that gauge trust in election forecasts. We generate simulated U.S. presidential election forecasts, vary win probabilities and outcomes, and present them to participants in a professional-looking website interface. In this website interface, we explore (1) four different uncertainty displays, (2) a technique for subjective probability correction, and (3) visual calibration that depicts an outcome with its forecast distribution. Our quantitative results suggest that text summaries and quantile dotplots engender the highest trust over time, with observable partisan differences. The probability correction and calibration show small-to-null effects on average. Complemented by our qualitative results, we provide design recommendations for conveying U.S. presidential election forecasts and discuss long-term trust in uncertainty communication. We provide preregistration, code, data, model files, and videos at https://doi.org/10.17605/OSF.IO/923E7.","2024","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Chi '24","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3613904.3642371 Number of pages: 24 Place: Honolulu, HI, USA tex.articleno: 389","","","","election forecasts; political communication; trust; uncertainty visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4QUKSCIG","conferencePaper","2020","Evans, Nathan; Edge, Darren; Larson, Jonathan; White, Christopher","News provenance: Revealing news text reuse at web-scale in an augmented news search experience","Extended abstracts of the 2020 CHI conference on human factors in computing systems","978-1-4503-6819-3","","10.1145/3334480.3375225","https://doi.org/10.1145/3334480.3375225","The media industry has a practice of reusing news content, which may be a surprise to news consumers. Whether by agreement or plagiarism, a lack of explicit citations makes it difficult to understand where news comes from and how it spreads. We reveal news provenance by reconstructing the history of near-duplicate news in the web index - identifying the origins of republished content and the impact of original content. By aggregating provenance information and presenting it as part of news search results, users may be able to make more informed decisions about which articles to read and which publishers to trust. We report on early analysis and user feedback, highlighting the critical tension between the desire for media transparency and the risks of disrupting an already fragile ecosystem.","2020","2024-07-07 16:25:38","2024-07-07 16:25:38","","1–8","","","","","","","Chi ea '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3334480.3375225 Number of pages: 8 Place: Honolulu, HI, USA","","","","media transparency; news media; news search; provenance analysis; provenance visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IYQP8MA2","conferencePaper","2020","Yang, Fumeng; Huang, Zhuanyi; Scholtz, Jean; Arendt, Dustin L.","How do visual explanations foster end users' appropriate trust in machine learning?","Proceedings of the 25th international conference on intelligent user interfaces","978-1-4503-7118-6","","10.1145/3377325.3377480","https://doi.org/10.1145/3377325.3377480","We investigated the effects of example-based explanations for a machine learning classifier on end users' appropriate trust. We explored the effects of spatial layout and visual representation in an in-person user study with 33 participants. We measured participants' appropriate trust in the classifier, quantified the effects of different spatial layouts and visual representations, and observed changes in users' trust over time. The results show that each explanation improved users' trust in the classifier, and the combination of explanation, human, and classification algorithm yielded much better decisions than the human and classification algorithm separately. Yet these visual explanations lead to different levels of trust and may cause inappropriate trust if an explanation is difficult to understand. Visual representation and performance feedback strongly affect users' trust, and spatial layout shows a moderate effect. Our results do not support that individual differences (e.g., propensity to trust) affect users' trust in the classifier. This work advances the state-of-the-art in trust-able machine learning and informs the design and appropriate use of automated systems.","2020","2024-07-07 16:25:38","2024-07-07 16:25:38","","189–201","","","","","","","Iui '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3377325.3377480 Number of pages: 13 Place: Cagliari, Italy","","","","classification; explainable artificial intelligence; human-machine collaboration; information visualization; supervised-learning; trust; trust calibration","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S4SH2USE","conferencePaper","2015","Angulo, Julio; Fischer-Hübner, Simone; Pulls, Tobias; Wästlund, Erik","Usable transparency with the data track: a tool for visualizing data disclosures","Proceedings of the 33rd annual ACM conference extended abstracts on human factors in computing systems","978-1-4503-3146-3","","10.1145/2702613.2732701","https://doi.org/10.1145/2702613.2732701","We present a prototype of the user interface of a transparency tool that displays an overview of a user's data disclosures to different online service providers and allows them to access data collected about them stored at the services' sides. We explore one particular type of visualization method consisting of tracing lines that connect a user's disclosed personal attributes to the service to which these attributes have been disclosed. We report on the ongoing iterative process of design of such visualization, the challenges encountered and the possibilities for future improvements.","2015","2024-07-07 16:25:38","2024-07-07 16:25:38","","1803–1808","","","","","","","Chi ea '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2702613.2732701 Number of pages: 6 Place: Seoul, Republic of Korea","","","","information visualisations; privacy; usability; usable transparency","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PLDK5LSC","conferencePaper","2016","Igouchkine, Oleg; Leaf, Nick; Ma, Kwan-Liu","Volume rendering dark matter simulations using cell projection and order-independent transparency","SIGGRAPH ASIA 2016 symposium on visualization","978-1-4503-4547-7","","10.1145/3002151.3002163","https://doi.org/10.1145/3002151.3002163","Dark matter simulations, performed using N-body methods with a finite set of tracer particles to discretize the initially uniform distribution of mass, are an invaluable method for exploring the formation of the universe. Definining a tetrahedral mesh in phase space-with the tracer particles at initialization serving as vertices-yields a more accurate density field. At later timesteps, the mesh self-intersects to an enormous degree, making pre-sorting impossible. Kaehler et al [2012] visualize the mesh using cell projection, but their method requires order-independent compositing, which limits its flexibility. Our work renders the mesh using state of the art order-independent transparency (OIT) techniques to composite fragments in correct depth order. This also allows us to render variables other than density, such as velocity. We implement a number of OIT optimizations to handle the high depth complexity (on the order of 107 depth layers for 2x109 particles) of the data. Our performance measurements show near-interactive framerates for our hybrid renderer despite the large number of depth layers.","2016","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Sa '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3002151.3002163 Number of pages: 8 Place: Macau tex.articleno: 8","","","","GPU acceleration; intersecting mesh; order-independent transparency; scientific visualization; volume rendering","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QMCKBFIZ","conferencePaper","2017","Dasgupta, Aritra; Burrows, Susannah; Han, Kyungsik; Rasch, Philip J.","Empirical analysis of the subjective impressions and objective measures of domain scientists' visual analytic judgments","Proceedings of the 2017 CHI conference on human factors in computing systems","978-1-4503-4655-9","","10.1145/3025453.3025882","https://doi.org/10.1145/3025453.3025882","Scientists often use specific data analysis and presentation methods familiar within their domain. But does high familiarity drive better analytical judgment? This question is especially relevant when familiar methods themselves can have shortcomings: many visualizations used conventionally for scientific data analysis and presentation do not follow established best practices. This necessitates new methods that might be unfamiliar yet prove to be more effective. But there is little empirical understanding of the relationships between scientists' subjective impressions about familiar and unfamiliar visualizations and objective measures of their visual analytic judgments. To address this gap and to study these factors, we focus on visualizations used for comparison of climate model performance. We report on a comprehensive survey-based user study with 47 climate scientists and present an analysis of: i) relationships among scientists' familiarity, their perceived levels of comfort, confidence, accuracy, and objective measures of accuracy, and ii) relationships among domain experience, visualization familiarity, and post-study preference.","2017","2024-07-07 16:25:38","2024-07-07 16:25:38","","1193–1204","","","","","","","Chi '17","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3025453.3025882 Number of pages: 12 Place: Denver, Colorado, USA","","","","climate; information visualization; preference; slope plot; taylor plot; trust; visual comparison","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QC3KUPWL","conferencePaper","2009","Inghelbrecht, Yanic","Object-oriented design with trace modeler and Trace4J","Proceedings of the 14th annual ACM SIGCSE conference on innovation and technology in computer science education","978-1-60558-381-5","","10.1145/1562877.1563017","https://doi.org/10.1145/1562877.1563017","We present two tools that make students more productive during various object-oriented design activities. The first one, Trace Modeler, is a smart UML sequence diagram editor that helps students understand and apply responsibility-driven design. The second tool, Trace4J, is used to record and process the execution of a java program. Both tools are complementary. Students use Trace4J to produce focused sequence diagrams for (part of) a program's execution. Trace Modeler's support for huge diagrams lets them navigate and understand the large results in the initial stages of their processing experiments.","2009","2024-07-07 16:25:38","2024-07-07 16:25:38","","375","","","","","","","ITiCSE '09","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1562877.1563017 Number of pages: 1 Place: Paris, France","","","","case tool; documentation; object-oriented design; program visualization; responsibility-driven design; sequence diagram; software development; tools; trace; UML; unified modeling language","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRHQ4ZKR","conferencePaper","2022","Ahn, Yongsu; Beigel, Eliana; Braun, Noah; Griffin, Collin; Linardi, Sera; Mickles, Blair; Rial, Emmaline","Improving citizen-initiated police reform efforts through interactive design: a case study in allegheny county","Proceedings of the 2nd ACM conference on equity and access in algorithms, mechanisms, and optimization","978-1-4503-9477-2","","10.1145/3551624.3555298","https://doi.org/10.1145/3551624.3555298","Increasing police accountability in the US has been an issue for decades, but citizen-initiated reform efforts have been less than effective at moving the needle on the issue. Our project aims to provide citizens and community organizers with a better understanding of the legal landscape of police accountability in Allegheny County, allowing them to more effectively advocate for reform. We do so by creating an open collaborative network that works to overcome the issues of data inaccessibility, data complexity, and the fragmentation of data across different municipalities. We engaged with community leaders, gathered contracts and other data on over 100 police departments in Allegheny County, and created a web platform to make this previously inaccessible information available to the public. In its creation, we also utilized visual representation to aid those engaging with the law to better understand and collaborate without being inhibited by complicated legal concepts.","2022","2024-07-07 16:25:38","2024-07-07 16:25:38","","","","","","","","","Eaamo '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3551624.3555298 Number of pages: 10 Place: Arlington, VA, USA tex.articleno: 13","","","","Interactive system; Legal corpus analysis; Legal visualization; Police accountability; Policing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6FDGLNU","conferencePaper","2019","An, Chuankai; N. Rockmore, Daniel","Open personalized navigation on the sandbox of wiki pages","Companion proceedings of the 2019 world wide web conference","978-1-4503-6675-5","","10.1145/3308560.3316755","https://doi.org/10.1145/3308560.3316755","In this paper we present a proof-of-concept of a visual navigation tool for a personalized “sandbox” of Wiki pages. The navigation tool considers multiple groups of algorithmic parameters and adapts to user activity via graphical user interfaces. The output is a 2D map of a subset of Wikipedia pages network which provides a different and broader visual representation – a map – in the neighborhood (according to some metric) of the pages around the page currently displayed in a browser. The representation schema includes the incorporation of a kind of transparency in the algorithmic parameters affecting the presentation of the landscape visualization, which in turn enables the delivery of a personalized canvas, designed by the user. A case study shows the combination of four different sourcing (i.e., identification and extraction of the neighboring pages) rules and three layouts over the same Wikipedia subnetwork. The basic schema is readily adapted to other search experiences and contexts.","2019","2024-07-07 16:25:38","2024-07-07 16:25:38","","1173–1179","","","","","","","Www '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3308560.3316755 Number of pages: 7 Place: San Francisco, USA","","","","Network Visualization; Transparent Navigation; Wikipedia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DS6J28VW","conferencePaper","2011","Nakamura, Mieko; Miyashita, Homei","Catchy account: a system for acquiring a realistic sense of expenditures","Proceedings of the 2nd augmented human international conference","978-1-4503-0426-9","","10.1145/1959826.1959855","https://doi.org/10.1145/1959826.1959855","In this paper, we propose a new household accounting system for realistically sensing expenditures. In 2D mode, expenditures are visualized through the placement of rectangles whose areas are proportional to the amount spent; thus, each item can be understood within the context of the total expenditure. In AR mode, spheres whose volumes are proportional to the amount spent appear to be floating in the camera image. The spheres fill the entire room and the size of expenditure can be realistically sensed. We designed this system in an attempt to ""augment"" the experience, so that the user can acquire a more realistic sense of expenditures.","2011","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Ah '11","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1959826.1959855 Number of pages: 2 Place: Tokyo, Japan tex.articleno: 29","","","","accounting; realistic sense; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XEW34BKE","conferencePaper","2020","Wright, Austin P; Shaikh, Omar; Park, Haekyu; Epperson, Will; Ahmed, Muhammed; Pinel, Stephane; Yang, Diyi; Chau, Duen Horng","RECAST: Interactive auditing of automatic toxicity detection models","Proceedings of the eighth international workshop of chinese CHI","978-1-4503-8815-3","","10.1145/3403676.3403691","https://doi.org/10.1145/3403676.3403691","As toxic language becomes nearly pervasive online, there has been increasing interest in leveraging the advancements in natural language processing (NLP) to automatically detect and remove toxic comments. Despite fairness concerns and limited interpretability, there is currently little work for auditing these systems in particular for end users. We present our ongoing work, Recast , an interactive tool for auditing toxicity detection models by visualizing explanations for predictions and providing alternative wordings for detected toxic speech. Recast displays the attention of toxicity detection models on user input, and provides an intuitive system for rewording impactful language within a comment with less toxic alternative words close in embedding space. Finally we propose a larger user study of Recast , with promising preliminary results, to validate it’s effectiveness and useability with end users.","2020","2024-07-07 16:25:39","2024-07-07 16:25:39","","80–82","","","","","","","Chinese CHI '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3403676.3403691 Number of pages: 3 Place: Honolulu, HI, USA","","","","Algorithmic Bias; Interactive Visualization; Machine Learning Fairness; Natural Language Processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETYFRE36","conferencePaper","2022","Wacharamanotham, Chat; Yang, Fumeng; Pu, Xiaoying; Sarma, Abhraneel; Padilla, Lace","Transparent practices for quantitative empirical research","Extended abstracts of the 2022 CHI conference on human factors in computing systems","978-1-4503-9156-6","","10.1145/3491101.3503760","https://doi.org/10.1145/3491101.3503760","Transparent research practices enable the research design, materials, analytic methods, and data to be thoroughly evaluated and potentially reproduced. The HCI community has recognized research transparency as one quality aspect of paper submission and review since CHI 2021. This course addresses HCI researchers and students who are already knowledgeable about experiment research design and statistical analysis. Building upon this knowledge, we will present current best practices and tools for increasing research transparency. We will cover relevant concepts and skills in Open Science, frequentist statistics, and Bayesian statistics, and uncertainty visualization. In addition to lectures, there will be hands-on exercises: The course participants will assess transparency practices in excerpts of quantitative reports, interactively explore implications of analytical choices using RStudio Cloud, and discuss their findings in small groups. In the final session, each participant will choose a case study based on their interest and assess its research transparency together with their classmates and instructors.","2022","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Chi ea '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3491101.3503760 Number of pages: 5 Place: New Orleans, LA, USA tex.articleno: 122","","","","Bayesian statistics; open science; transparent statistics; uncertainty visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UI2W5NQ","conferencePaper","2006","Zhao, Lin; Grant, Julia; Collopy, Fred","The design of an interactive and dynamic representation of the firm","CHI '06 extended abstracts on human factors in computing systems","1-59593-298-4","","10.1145/1125451.1125740","https://doi.org/10.1145/1125451.1125740","Interpretation and audit of financial information is a significant undertaking that must rest on a fuller understanding of the firm and its operations. A pictorial representation of firm activity offers promise for supporting this requirement. After reviewing the literature related to visualizations, we describe the design of an interactive animated version of the cycle model. Business Animator assists users in developing an intuitive sense about the cycle model itself, while exploring and visualizing how firms at various stages of growth, sustenance, and decay are affected by specific operating decisions. Principles and findings from the accounting and information systems literatures were used to drive the design of the representation and software used to control it. This resulting system adds depth to traditional accounting representations by conveying information about the momentum of the firm's activities, the rate of change at which various activities are occurring. The animation facilitates identification of backlogs or breaks in operating processes, thus increasing understanding of the firm's financial health.","2006","2024-07-07 16:25:39","2024-07-07 16:25:39","","1583–1588","","","","","","","Chi ea '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1125451.1125740 Number of pages: 6 Place: Montréal, Québec, Canada","","","","accounting information systems; animation; information representation; interactivity; simulation; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F6M9QIHT","conferencePaper","2023","Wacharamanotham, Chat; Yang, Fumeng; Pu, Xiaoying; Sarma, Abhraneel","Transparent practices for quantitative empirical research","Extended abstracts of the 2023 CHI conference on human factors in computing systems","978-1-4503-9422-2","","10.1145/3544549.3574168","https://doi.org/10.1145/3544549.3574168","Transparent research practices enable the research design, materials, analytic methods, and data to be thoroughly evaluated and potentially reproduced. The HCI community has recognized research transparency as one quality aspect of paper submission and review since CHI 2021. This course presents current best practices and tools that increase research transparency for HCI researchers and students. The course will be three online lectures and one in-person lab session. The lectures will cover the most relevant concepts, guidelines, and practices in Open Science, frequentist statistics, Bayesian statistics, and uncertainty visualization. In the lab session, the course participants will interactively explore implications of analytical choices using RStudio in pairs or small group and receive tailored feedback from instructors. For any participants cannot come to Hamburg, we will provide a parallel online session.","2023","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Chi ea '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3544549.3574168 Number of pages: 5 Place: Hamburg, Germany tex.articleno: 559","","","","Bayesian statistics; open science; transparent statistics; uncertainty visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"656NRXRJ","conferencePaper","2015","Xu, Rui; Tanaka, Satoshi; Hasegawa, Kyoko; Sheng, Wang; Tateyama, Tomoko; Chen, Yen-Wei; Kido, Shoji","Transparent visualization of large-scale and complex polygon meshes using a stochastic point-based rendering method","SIGGRAPH asia 2015 visualization in high performance computing","978-1-4503-3929-2","","10.1145/2818517.2818528","https://doi.org/10.1145/2818517.2818528","Efficient and reliable transparent visualization of large and complex surface data is important in many applications, including the visualization of medical data. Among the many methods, depth-peeling is an efficient solution for rendering polygon meshes transparently; however, the computational cost is related to the number of passes through the peeled geometry. Therefore, the depth-peeling method cannot efficiently render large and complex polygon meshes that require many passes through the geometry. In this paper, we solve this problem using a stochastic point-based rendering (SPBR) method. We use two types of large-scale and complex polygon meshes that have 5,744,376 and 4,800,644 triangles in the experiments. The rendering speed of our method is 3-5 times faster than that of the depth-peeling method for an image resolution of 512 × 512. Additionally, the SPBR method has an inherent visual effect: the outlines of target polygon meshes can be automatically enhanced. This makes the results of the SPBR method more vivid and comprehensible than those of the depth-peeling method.","2015","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Sa '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2818517.2818528 Number of pages: 4 Place: Kobe, Japan tex.articleno: 9","","","","large-scale polygons; stochastic point-based rendering; transparent visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RGAZ6XUI","conferencePaper","2006","Iwai, Takafumi; Kitada, Sohei; Higaki, Mariko; Deguchi, Mizuki; Kaijima, Kazuya; Wakita, Akira","Paravision: the entertaining visualizer in public space","Proceedings of the 2006 ACM SIGCHI international conference on advances in computer entertainment technology","1-59593-380-8","","10.1145/1178823.1178928","https://doi.org/10.1145/1178823.1178928","In this paper, we describe the dynamic sign system in public space using RFID and transparent screen. This system called Paravision is made to experiment whether signs can be entertaining. With all users having their own RFID tags, and RFID reader placed in several places at site, Paravision can project dynamic signs on the transparent screen.","2006","2024-07-07 16:25:39","2024-07-07 16:25:39","","90–es","","","","","","","Ace '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1178823.1178928 Place: Hollywood, California, USA","","","","information design; information visualization; public ambient display; RFID; transparent screen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UB82GLQS","conferencePaper","2015","Reda, Khairi; Johnson, Andrew E.; Papka, Michael E.; Leigh, Jason","Effects of display size and resolution on user behavior and insight acquisition in visual exploration","Proceedings of the 33rd annual ACM conference on human factors in computing systems","978-1-4503-3145-6","","10.1145/2702123.2702406","https://doi.org/10.1145/2702123.2702406","Large high-resolution displays are becoming increasingly common in research settings, providing data scientists with visual interfaces for the analysis of large datasets. Numerous studies have demonstrated unique perceptual and cognitive benefits afforded by these displays in visual analytics and information visualization tasks. However, the effects of these displays on knowledge discovery in exploratory visual analysis are still poorly understood. We present the results of a small-scale study to better understand how display size and resolution affect insight. Analyzing participants' verbal statements, we find preliminary evidence that larger displays with more pixels can significantly increase the number of discoveries reported during visual exploration, while yielding broader, more integrative insights. Furthermore, we find important differences in how participants performed the same visual exploration task using displays of varying sizes. We tie these results to extant work and propose explanations by considering the cognitive and interaction costs associated with visual exploration.","2015","2024-07-07 16:25:39","2024-07-07 16:25:39","","2759–2768","","","","","","","Chi '15","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2702123.2702406 Number of pages: 10 Place: Seoul, Republic of Korea","","","","cognitive biases; exploratory visual analysis; large high-resolution displays; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YTGUG3ZA","conferencePaper","2012","Stuart, H. Colleen; Dabbish, Laura; Kiesler, Sara; Kinnaird, Peter; Kang, Ruogu","Social transparency in networked information exchange: a theoretical framework","Proceedings of the ACM 2012 conference on computer supported cooperative work","978-1-4503-1086-4","","10.1145/2145204.2145275","https://doi.org/10.1145/2145204.2145275","An emerging Internet trend is greater social transparency, such as the use of real names in social networking sites, feeds of friends' activities, traces of others' re-use of content, and visualizations of team interactions. Researchers lack a systematic way to conceptualize and evaluate social transparency. The purpose of this paper is to develop a framework for thinking about social transparency. This framework builds upon multiple streams of research, including prior work in CSCW on social translucence, awareness, and visual analytics, to describe three dimensions of online behavior that can be made transparent. Based on the framework, we consider the social inferences transparency supports and introduce a set of research questions about social transparency's implications for computer-supported collaborative work and information exchange.","2012","2024-07-07 16:25:39","2024-07-07 16:25:39","","451–460","","","","","","","Cscw '12","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2145204.2145275 Number of pages: 10 Place: Seattle, Washington, USA","","","","awareness; collaboration; information exchange; innovation; social translucence; social transparency; theory; visualizations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6UAR9VXP","conferencePaper","2020","Shapiro, Ben Rydal; Meng, Amanda; O'Donnell, Cody; Lou, Charlotte; Zhao, Edwin; Dankwa, Bianca; Hostetler, Andrew","Re-shape: a method to teach data ethics for data science education","Proceedings of the 2020 CHI conference on human factors in computing systems","978-1-4503-6708-0","","10.1145/3313831.3376251","https://doi.org/10.1145/3313831.3376251","Data has become central to the technologies and services that human-computer interaction (HCI) designers make, and the ethical use of data in and through these technologies should be given critical attention throughout the design process. However, there is little research on ethics education in computer science that explicitly addresses data ethics. We present and analyze Re-Shape, a method to teach students about the ethical implications of data collection and use. Re-Shape, as part of an educational environment, builds upon the idea of cultivating care and allows students to collect, process, and visualize their physical movement data in ways that support critical reflection and coordinated classroom activities about data, data privacy, and human-centered systems for data science. We also use a case study of Re-Shape in an undergraduate computer science course to explore prospects and limitations of instructional designs and educational technology such as Re-Shape that leverage personal data to teach data ethics.","2020","2024-07-07 16:25:39","2024-07-07 16:25:39","","1–13","","","","","","","Chi '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3313831.3376251 Number of pages: 13 Place: Honolulu, HI, USA","","","","care ethics; computer science education; data ethics; data literacy; data privacy; data science education; information visualization; interaction geography slicer; re-shape","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HSQ63U2F","conferencePaper","2006","Elmqvist, Niklas; Tsigas, Philippas","TrustNeighborhoods in a nutshell","Proceedings of the 2006 ACM symposium on software visualization","1-59593-464-2","","10.1145/1148493.1148538","https://doi.org/10.1145/1148493.1148538","In this short paper, we review the TrustNeighborhoods system for 2D and 3D visualization of trust relationships on the Internet for novice and intermediate-level users. Intended to convey a tangible mental model of security, the system is based on the concept of ""circles of relationship"" as a model for computer usage proposed by Ben Shneiderman, and uses a strong visual metaphor of a multi-layered city or fortress representing the computer network. Trust relationships are shown using an intuitive geographic relation. The tool has both 2D and 3D modes, one intended for configuration and trust management, the other for non-intrusive situational awareness of security for the local computer.","2006","2024-07-07 16:25:39","2024-07-07 16:25:39","","189–190","","","","","","","SoftVis '06","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1148493.1148538 Number of pages: 2 Place: Brighton, United Kingdom","","","","security visualization; trust visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XTQIUB3E","conferencePaper","2020","Snyder, Jaime","Visualizing personal rhythms: a critical visual analysis of mental health in flux","Proceedings of the 2020 ACM designing interactive systems conference","978-1-4503-6974-9","","10.1145/3357236.3395463","https://doi.org/10.1145/3357236.3395463","Visualizations of personal data in self-tracking systems can make even subtle shifts in mental and physical states observable, greatly influencing how health and wellness goals are set, pursued, and achieved. At the same time, recent work in data ethics cautions that standardized models can have unintended negative consequences for some user groups. Through collaborative design and critical visual analysis, this study contrasts conventional visualizations of personal data with the ways that vulnerable populations represent their lived experiences. Participants self-tracked to manage bipolar disorder, a mental illness characterized by severe and unpredictable mood changes. During design sessions, each created a series of timeline drawings depicting their experiences with mental health. Examples of adaptive and vernacular design, these images use both normative standards and individualized graphic modifications. Analysis shows that conventional visual encodings can support facets of self-assessment while also imposing problematic normative standards onto deeply personal experiences.","2020","2024-07-07 16:25:39","2024-07-07 16:25:39","","269–281","","","","","","","Dis '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3357236.3395463 Number of pages: 13 Place: Eindhoven, Netherlands","","","","co-design; critical visual analysis; data ethics; mental health; personal visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U7VJKHBN","conferencePaper","2019","Kong, Ha-Kyung; Liu, Zhicheng; Karahalios, Karrie","Trust and recall of information across varying degrees of title-visualization misalignment","Proceedings of the 2019 CHI conference on human factors in computing systems","978-1-4503-5970-2","","10.1145/3290605.3300576","https://doi.org/10.1145/3290605.3300576","Visualizations are emerging as a means of spreading digital misinformation. Prior work has shown that visualization interpretation can be manipulated through slanted titles that favor only one side of the visual story, yet people still think the visualization is impartial. In this work, we study whether such effects continue to exist when titles and visualizations exhibit greater degrees of misalignment: titles whose message differs from the visually cued message in the visualization, and titles whose message contradicts the visualization. We found that although titles with a contradictory slant triggered more people to identify bias compared to titles with a miscued slant, visualizations were persistently perceived as impartial by the majority. Further, people's recall of the visualization's message more frequently aligned with the titles than the visualization. Based on these results, we discuss the potential of leveraging textual components to detect and combat visual-based misinformation with text-based slants.","2019","2024-07-07 16:25:39","2024-07-07 16:25:39","","1–13","","","","","","","Chi '19","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3290605.3300576 Number of pages: 13 Place: Glasgow, Scotland Uk","","","","confirmation bias; misinformation; visualization title","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9G967X2T","conferencePaper","2020","Spinde, Timo; Hamborg, Felix; Donnay, Karsten; Becerra, Angelica; Gipp, Bela","Enabling news consumers to view and understand biased news coverage: a study on the perception and visualization of media bias","Proceedings of the ACM/IEEE joint conference on digital libraries in 2020","978-1-4503-7585-6","","10.1145/3383583.3398619","https://doi.org/10.1145/3383583.3398619","Traditional media outlets are known to report political news in a biased way, potentially affecting the political beliefs of the audience and even altering their voting behaviors. Many researchers focus on automatically detecting and identifying media bias in the news, but only very few studies exist that systematically analyze how theses biases can be best visualized and communicated. We create three manually annotated datasets and test varying visualization strategies. The results show no strong effects of becoming aware of the bias of the treatment groups compared to the control group, although a visualization of hand-annotated bias communicated bias in-stances more effectively than a framing visualization. Showing participants an overview page, which opposes different viewpoints on the same topic, does not yield differences in respondents' bias perception. Using a multilevel model, we find that perceived journalist bias is significantly related to perceived political extremeness and impartiality of the article.","2020","2024-07-07 16:25:39","2024-07-07 16:25:39","","389–392","","","","","","","Jcdl '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3383583.3398619 Number of pages: 4 Place: Virtual Event, China","","","","bias visualization; news bias; news slant; perception of news","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2J4Q8AK","conferencePaper","2016","Graells-Garrido, Eduardo; Lalmas, Mounia; Baeza-Yates, Ricardo","Encouraging diversity- and representation-awareness in geographically centralized content","Proceedings of the 21st international conference on intelligent user interfaces","978-1-4503-4137-0","","10.1145/2856767.2856775","https://doi.org/10.1145/2856767.2856775","In centralized countries, not only population, media and economic power are concentrated, but people give more attention to central locations. While this is not inherently bad, this behavior extends to micro-blogging platforms: central locations get more attention in terms of information flow. In this paper we study the effects of an information filtering algorithm that decentralizes content in such platforms. Particularly, we found that users from non-central locations were not able to identify the geographical diversity on timelines generated by the algorithm, which were diverse by construction. To make users see the inherent diversity, we define a design rationale to approach this problem, focused on the treemap visualization technique. Then, we deployed an"" in the wild"" implementation of our proposed system. On one hand, we found that there are effects of centralization in exploratory user behavior. On the other hand, we found that the treemap was able to make users see the inherent geographical diversity of timelines. We measured these effects based on how users engaged with content filtered by the algorithm. With these results in mind, we propose practical actions for micro-blogging platforms to account for the differences and biased behavior induced by centralization.","2016","2024-07-07 16:25:39","2024-07-07 16:25:39","","7–18","","","","","","","Iui '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2856767.2856775 Number of pages: 12 Place: Sonoma, California, USA","","","","centralization; information filtering; information visualization; location bias","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZFKGTTSB","conferencePaper","2023","Borela, Rodrigo; Roy, Nimisha","Creating equitable grading practices with rubrics: a teaching assistant training activity","Proceedings of the 2023 ACM conference on international computing education research - volume 2","978-1-4503-9975-3","","10.1145/3568812.3603485","https://doi.org/10.1145/3568812.3603485","Manually grading coding assignments in large computer science (CS) classes is a challenging logistical task. The evaluation of code correctness is subjective, leading to grading bias and inconsistencies. This problem is exacerbated when multiple teaching assistants (TAs) grade different submissions of the same problem.One potential solution to these challenges is the use of rubrics, which offer a structured approach to grading by adopting specific criteria for the quality of student work [1, 2]. They can help mitigate instructors' implicit biases and minimize grading variance even when multiple raters are involved [2, 3]. Moreover, rubrics can motivate students to improve their work [4], enhance their learning in CS courses [4], and provide an objective evaluation of multimedia projects [5].However, validity, reliability, and fairness issues still apply to their use [6]. To account for the subjective nature of coding, assigning partial points based on conceptual understanding rather than just the final output promotes equitable grading since the final output may not always reflect the student's grasp of the topics [6]. Therefore, rubrics must be designed to be simple, specific, and easy to understand for instructors, graders, and students.In this study, we conducted a hands-on TA training workshop to explore the effectiveness of rubrics in grading coding assignments in a core undergraduate CS course. The workshop provided participants with rubrics and rater training to assess the impact of rubrics on grading bias and consistency. Additionally, the workshop introduced the use of partial points based on students' conceptual understanding, aiming to promote fair and objective grading while also addressing the limitations of this approach.The workshop was conducted for distinct groups of TAs, totaling 50 participants. Firstly, participants were given two sample incorrect solutions to a problem and asked to grade them at their own discretion. In the second round, they re-graded the solutions using a rubric with assigned points to different solution components. The results of the two grading rounds were reported anonymously, and a real-time graph displayed the grade distribution. Statistical analysis revealed a significant reduction in grade variance for both student groups, from 5.55 to 0.66 and from 4.28 to 1.11, respectively, on a scale from 1 to 10. This quantitative and visual analysis helped TAs understand the importance of rubrics and enabled them to discuss biases and best practices for developing and deploying rubrics. TAs' informal feedback indicated the workshop's effectiveness in demonstrating the relevance of creating good rubrics. The workshop design expands on previous workshops for other disciplines by showcasing the unique aspects of grading in computer science, such as the different approaches to solving coding problems and the introduction of visualizations to understand grading variances.This workshop showcases the application of rubrics and quantitative data visual analytics to promote equitable grading practices and underscore the significance of ethical issues in CS education training. Inspired by rubric-utilizing workshops in math, chemistry, and biology, we have innovated by accommodating the varied problem-solving paths inherent in coding, thus emphasizing conceptual over procedural grading. Unique to our approach is the integration of a data visualization component to help understand grading variance. This workshop's design can be extended to various pedagogical topics, allowing real-time analysis of small-scale experiments, thus broadening its applicability and shaping future teaching strategies.","2023","2024-07-07 16:25:39","2024-07-07 16:25:39","","26–27","","","","","","","Icer '23","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3568812.3603485 Number of pages: 2 Place: Chicago, IL, USA","","","","Data Visualization; Grading Fairness; Rubrics; Teaching Assistant Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HL2ECAGZ","journalArticle","2016","Tintarev, Nava; O'donovan, John; Felfernig, Alexander","Introduction to the special issue on human interaction with artificial advice givers","ACM Transactions on Interactive Intelligent Systems","","2160-6455","10.1145/3014432","https://doi.org/10.1145/3014432","Many interactive systems in today’s world can be viewed as providing advice to their users. Commercial examples include recommender systems, satellite navigation systems, intelligent personal assistants on smartphones, and automated checkout systems in supermarkets. We will call these systems that support people in making choices and decisions artificial advice givers (AAGs): They propose and evaluate options while involving their human users in the decision-making process. This special issue addresses the challenge of improving the interaction between artificial and human agents. It answers the question of how an agent of each type (human and artificial) can influence and understand the reasoning, working models, and conclusions of the other agent by means of novel forms of interaction. To address this challenge, the articles in the special issue are organized around three themes: (a) human factors to consider when designing interactions with AAGs (e.g., over- and under-reliance, overestimation of the system’s capabilities), (b) methods for supporting interaction with AAGs (e.g., natural language, visualization, and argumentation), and (c) considerations for evaluating AAGs (both criteria and methodology for applying them).","2016-12","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","4","6","","ACM Trans. Interact. Intell. Syst.","","","","","","","","","","","","","","","Citation Key: 10.1145/3014432 Number of pages: 12 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 26 tex.issue_date: December 2016","","","","advising agents; Agent-based interaction; anthropomorphism; argumentation; emotions; facial actions; feedforward and feedback; gestures; human argumentation; human decision making; human-agent interaction; human-like computing; interaction paradigms; recommendation; reliance on automation; use image; vague language; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DWRDWC6J","journalArticle","2018","Talkad Sukumar, Poorna; Metoyer, Ronald; He, Shuai","Making a pecan pie: Understanding and supporting the holistic review process in admissions","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3274438","https://doi.org/10.1145/3274438","Holistic reviews are a common practice employed by universities in the USA to make admissions decisions. It is an individualized review process where reviewers assess an applicant's potential by considering various criteria including academic metrics, adversities faced, and personal attributes. While the factors considered in such reviews are broadly known, a detailed walk-through of the process is absent in existing literature. This is important to understand what is done in practice and to identify opportunities for technological interventions to support the complex and changing process. We employed cognitive task analysis and a socio-organizational approach to understand the holistic review process at a highly-selective, private university. We found the process to be nuanced and complex owing its complexity both to the numerous variables involved and the reviewers' thought processes. We present a rigorous, structured characterization of the review process and suggest possible leverage points for applying visualization decision-support tools.","2018-11","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","CSCW","2","","","","","","","","","","","","","","","","","Citation Key: 10.1145/3274438 Number of pages: 22 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 169 tex.issue_date: November 2018","","","","cognitive bias; decision making; holistic college admissions; information visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"74GRYZM8","journalArticle","2022","Lam, Michelle S.; Gordon, Mitchell L.; Metaxa, Danaë; Hancock, Jeffrey T.; Landay, James A.; Bernstein, Michael S.","End-user audits: a system empowering communities to lead large-scale investigations of harmful algorithmic behavior","Proc. ACM Hum.-Comput. Interact.","","","10.1145/3555625","https://doi.org/10.1145/3555625","Because algorithm audits are conducted by technical experts, audits are necessarily limited to the hypotheses that experts think to test. End users hold the promise to expand this purview, as they inhabit spaces and witness algorithmic impacts that auditors do not. In pursuit of this goal, we propose end-user audits-system-scale audits led by non-technical users-and present an approach that scaffolds end users in hypothesis generation, evidence identification, and results communication. Today, performing a system-scale audit requires substantial user effort to label thousands of system outputs, so we introduce a collaborative filtering technique that leverages the algorithmic system's own disaggregated training data to project from a small number of end user labels onto the full test set. Our end-user auditing tool, IndieLabel, employs these predicted labels so that users can rapidly explore where their opinions diverge from the algorithmic system's outputs. By highlighting topic areas where the system is under-performing for the user and surfacing sets of likely error cases, the tool guides the user in authoring an audit report. In an evaluation of end-user audits on a popular comment toxicity model with 17 non-technical participants, participants both replicated issues that formal audits had previously identified and also raised previously underreported issues such as under-flagging on veiled forms of hate that perpetuate stigma and over-flagging of slurs that have been reclaimed by marginalized communities.","2022-11","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","CSCW2","6","","","","","","","","","","","","","","","","","Citation Key: 10.1145/3555625 Number of pages: 34 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 512 tex.issue_date: November 2022","","","","algorithm auditing; algorithmic fairness; human-centered ai; interactive visualization; machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H9AY4V2R","conferencePaper","2021","Zehrung, Rachael; Singhal, Astha; Correll, Michael; Battle, Leilani","Vis ex machina: An analysis of trust in human versus algorithmically generated visualization recommendations","Proceedings of the 2021 CHI conference on human factors in computing systems","978-1-4503-8096-6","","10.1145/3411764.3445195","https://doi.org/10.1145/3411764.3445195","More visualization systems are simplifying the data analysis process by automatically suggesting relevant visualizations. However, little work has been done to understand if users trust these automated recommendations. In this paper, we present the results of a crowd-sourced study exploring preferences and perceived quality of recommendations that have been positioned as either human-curated or algorithmically generated. We observe that while participants initially prefer human recommenders, their actions suggest an indifference for recommendation source when evaluating visualization recommendations. The relevance of presented information (e.g., the presence of certain data fields) was the most critical factor, followed by a belief in the recommender’s ability to create accurate visualizations. Our findings suggest a general indifference towards the provenance of recommendations, and point to idiosyncratic definitions of visualization quality and trustworthiness that may not be captured by simple measures. We suggest that recommendation systems should be tailored to the information-foraging strategies of specific users.","2021","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Chi '21","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3411764.3445195 Number of pages: 12 Place: Yokohama, Japan tex.articleno: 602","","","","algorithmic trust; automation; recommendation source; Visualization recommendation systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"243LZUKY","journalArticle","2017","Li, Yi-Na; Zhang, Kang; Li, Dong-Jin","How dimensional and semantic attributes of visual sign influence relative value estimation","ACM Trans. Appl. Percept.","","1544-3558","10.1145/3059006","https://doi.org/10.1145/3059006","High-quality decision making requires accurate estimation of relative values. The perceptual bias when estimating relative values displayed by a visual sign may weaken the accuracy and cause misjudgment. This research explores the heuristic estimation of relative values using visual cues, namely linear, areal, and volumetric information. We conduct experiments to empirically test the influences of dimensional information on perceptual biases. First, we investigate the conspicuity of areal information. Our experiments indicate that the responses of participants instructed to estimate rates defined by either linear or volumetric information are biased by the corresponding rates determined by areal information. Second, visual cues implying three-dimensional information (e.g., depth) can lead to overestimation. Third, we probe the influence of vividness as the boundary condition on relative value estimation. Empirical evidence on perceptual bias sheds light on the pragmatics of visual signs, helps suggest guidelines for visual persuasions, and improves decision-making quality.","2017-04","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","3","14","","","","","","","","","","","","","","","","","Citation Key: 10.1145/3059006 Number of pages: 20 Place: New York, NY, USA Publisher: Association for Computing Machinery tex.articleno: 18 tex.issue_date: July 2017","","","","dimensional information; Information visualization; perceptual bias; relative value estimation; visual cue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VWVJBN56","conferencePaper","2022","Bao, Calvin S.; Li, Siyao; Flores, Sarah G; Correll, Michael; Battle, Leilani","Recommendations for visualization recommendations: Exploring preferences and priorities in public health","Proceedings of the 2022 CHI conference on human factors in computing systems","978-1-4503-9157-3","","10.1145/3491102.3501891","https://doi.org/10.1145/3491102.3501891","The promise of visualization recommendation systems is that analysts will be automatically provided with relevant and high-quality visualizations that will reduce the work of manual exploration or chart creation. However, little research to date has focused on what analysts value in the design of visualization recommendations. We interviewed 18 analysts in the public health sector and explored how they made sense of a popular in-domain dataset1 in service of generating visualizations to recommend to others. We also explored how they interacted with a corpus of both automatically- and manually-generated visualization recommendations, with the goal of uncovering how the design values of these analysts are reflected in current visualization recommendation systems. We find that analysts champion simple charts with clear takeaways that are nonetheless connected with existing semantic information or domain hypotheses. We conclude by recommending that visualization recommendation designers explore ways of integrating context and expectation into their systems.","2022","2024-07-07 16:25:39","2024-07-07 16:25:39","","","","","","","","","Chi '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3491102.3501891 Number of pages: 17 Place: New Orleans, LA, USA tex.articleno: 411","","","","algorithmic trust; automation; recommendation source; Visualization recommendation systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X3NP8F6V","conferencePaper","2016","Li, Yi-Na; Li, Dong-Jin","How people deploy dimensional information to estimate relative values","Proceedings of the 9th international symposium on visual information communication and interaction","978-1-4503-4149-3","","10.1145/2968220.2968240","https://doi.org/10.1145/2968220.2968240","A high quality decision-making requires accurate estimations of relative values. When one estimates relative values relying on visual stimuli, perceptual bias may weaken the accuracy and bring about risks. This research explores how people estimate relative values heuristically using visual cues with different dimensional information, i.e., linear, areal and volumetric information. We conduct experiments to empirically testify the influences of dimensional information on perceptual biases. First, we confirm the conspicuity of areal information. When instructed to estimate rates exclusively relying on either linear or volumetric information, people would inevitably be influenced by the corresponding rates determined by areal information. Second, we provide evidences that visual cues implying depth would lead to overestimates. This research provides implications for designers to enhance the power of visual persuasions, and for users to improve their decision making quality.","2016","2024-07-07 16:25:39","2024-07-07 16:25:39","","83–90","","","","","","","Vinci '16","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2968220.2968240 Number of pages: 8 Place: Dallas, TX, USA","","","","dimensional information; Information visualization; perceptual bias; relative value estimation; visual cue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LRJ6UMFP","conferencePaper","2020","Yu, Bowen; Yuan, Ye; Terveen, Loren; Wu, Zhiwei Steven; Forlizzi, Jodi; Zhu, Haiyi","Keeping designers in the loop: Communicating inherent algorithmic trade-offs across multiple objectives","Proceedings of the 2020 ACM designing interactive systems conference","978-1-4503-6974-9","","10.1145/3357236.3395528","https://doi.org/10.1145/3357236.3395528","Artificial intelligence algorithms have been used to enhance a wide variety of products and services, including assisting human decision making in high-stake contexts. However, these algorithms are complex and have trade-offs, notably between prediction accuracy and fairness to population subgroups. This makes it hard for designers to understand algorithms and design products or services in a way that respects users' goals, values, and needs. We proposed a method to help designers and users explore algorithms, visualize their trade-offs, and select algorithms with trade-offs consistent with their goals and needs. We evaluated our method on the problem of predicting criminal defendants' likelihood to re-offend through (i) a large-scale Amazon Mechanical Turk experiment, and (ii) in-depth interviews with domain experts. Our evaluations show that our method can help designers and users of these systems better understand and navigate algorithmic trade-offs. This paper contributes a new way of providing designers the ability to understand and control the outcomes of algorithmic systems they are creating.","2020","2024-07-07 16:25:39","2024-07-07 16:25:39","","1245–1257","","","","","","","Dis '20","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3357236.3395528 Number of pages: 13 Place: Eindhoven, Netherlands","","","","algorithmic fairness; algorithmic trade-offs; case study; criminal prediction; experimental design; interactive visualization; interview study","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WT9MFZ6","conferencePaper","2010","Balakrishnan, Aruna D.; Fussell, Susan R.; Kiesler, Sara; Kittur, Aniket","Pitfalls of information access with visualizations in remote collaborative analysis","Proceedings of the 2010 ACM conference on computer supported cooperative work","978-1-60558-795-0","","10.1145/1718918.1718988","https://doi.org/10.1145/1718918.1718988","In a world of widespread information access, information can overwhelm collaborators, even with visualizations to help. We extend prior work to study the effect of shared information on collaboration. We analyzed the success and discussion process of remote pairs trying to identify a serial killer in multiple crime cases. Each partner had half of the evidence, or each partner had all the available evidence. Pairs also used one of three tools: spreadsheet only (control condition), unshared visualizations, or shared visualization. Visualizations improved analysis over the control condition but this improvement depended on how much evidence each partner had. When each partner possessed all the evidence with visualizations, discussion flagged and pairs showed evidence of more confirmation bias. They discussed fewer hypotheses and persisted on the wrong hypothesis. We discuss the possible reasons for this phenomenon and implications for design of remote collaboration systems to incorporate awareness of intermediate processes important to collaborative success.","2010","2024-07-07 16:25:39","2024-07-07 16:25:39","","411–420","","","","","","","Cscw '10","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/1718918.1718988 Number of pages: 10 Place: Savannah, Georgia, USA","","","","computer-mediated communication; confirmation bias; empirical studies; experiment; information overload; information sharing; information visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4LF4ZQI","conferencePaper","2023","Li, Kaodui; Yu, Xinyi; Chu, Yanhong; Yang, Xue; Xu, Haochen; Shen, Cuiqi","Research on the competency framework of management accounting profession in the age of ""great wisdom moving cloud"" of china based on knowledge graph","Proceedings of the 7th international conference on information systems engineering","978-1-4503-9788-9","","10.1145/3573926.3573938","https://doi.org/10.1145/3573926.3573938","As China's economy steps into the new normal and its growth changes from extensive growth based on scale and speed to intensive growth based on quality and efficiency, enterprises are in urgent need of management accounting profession to help them improve their capital structure and realize transformation and upgrading. However, most of the enterprises in China still focus on the traditional accounting model and lack a reasonable and perfect competency framework of management accounting profession. This thesis, based on the data of the general database of online publications of Chinese academic journals and by means of information visualization software (Gephi) and keywords co-occurrence network analysis, makes a visual analysis of the documents on the competency framework of management accounting profession from the perspective of time distribution, high frequency keywords, authors and source journals. It explores the knowledge graph of research hot spots on the competency framework of management accounting profession and analyses its overall development trend.","2023","2024-07-07 16:25:39","2024-07-07 16:25:39","","65–72","","","","","","","Icise '22","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/3573926.3573938 Number of pages: 8 Place: Charleston, SC, USA","","","","Competency Framework; Knowledge Graph; Management Accounting; Visualization Analytics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WF3TT33S","conferencePaper","2014","Graells-Garrido, Eduardo","Enhancing web activities with information visualization","Proceedings of the 23rd international conference on world wide web","978-1-4503-2745-9","","10.1145/2567948.2567958","https://doi.org/10.1145/2567948.2567958","Many activities people perform on the Web are biased, including activities like reading news, searching for information and connecting with people. Sometimes these biases are inherent in social behavior (like homophily), and sometimes they are external as they affect the system (like media bias). In this thesis proposal, we describe our approach to use information visualization to enhance Web activities performed by regular people (i.e., non-experts) We understand enhancing as reducing bias effects and generating an engaging response from users. Our methodology is based on case studies. We select a Web activity, identify the biases that affect it, and evaluate how the biases affect a population from online social networks using web mining techniques, and then, we design a visualization following an interactive and playful design approach to diminish the previously identified biases. We propose to evaluate the effect of our visualization designs in user studies by comparing them with state-of-the-art techniques considering a playful experiences framework.","2014","2024-07-07 16:25:39","2024-07-07 16:25:39","","39–44","","","","","","","WWW '14 companion","","","","Association for Computing Machinery","New York, NY, USA","","","","","","","","Citation Key: 10.1145/2567948.2567958 Number of pages: 6 Place: Seoul, Korea","","","","biases; information visualization; playful experiences; web activities; web mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""